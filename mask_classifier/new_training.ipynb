{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['with_mask', 'without_mask']\n"
     ]
    }
   ],
   "source": [
    "data_dir = r'C:\\Users\\aiforesee\\Google Drive (bimapriambodowr@gmail.com)\\Digital Rise Indonesia\\Object Detection\\Masker Detection - Resnet\\experiements\\data'\n",
    "def load_split_train_test(datadir, valid_size = .25):\n",
    "    train_transforms = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                           transforms.CenterCrop(224),\n",
    "                                           transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0),\n",
    "                                           transforms.RandomAffine(degrees = (-45,45), translate=None, scale=None, shear=None, resample=False, fillcolor=0),\n",
    "                                           transforms.RandomRotation((-45,45)),\n",
    "                                           transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                           transforms.RandomPerspective(distortion_scale=0.5, p=0.5, interpolation=3, fill=0),\n",
    "                                           transforms.RandomVerticalFlip(p=0.5),\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False),\n",
    "                                           transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                          ])\n",
    "    test_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                          transforms.CenterCrop(224),\n",
    "                                          transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0),\n",
    "                                           transforms.RandomAffine(degrees = (-45,45), translate=None, scale=None, shear=None, resample=False, fillcolor=0),\n",
    "                                           transforms.RandomRotation((-45,45)),\n",
    "                                           transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                           transforms.RandomPerspective(distortion_scale=0.5, p=0.5, interpolation=3, fill=0),\n",
    "                                           transforms.RandomVerticalFlip(p=0.5),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False),\n",
    "                                          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                         ])\n",
    "    train_data = datasets.ImageFolder(datadir,       \n",
    "                    transform=train_transforms)\n",
    "    test_data = datasets.ImageFolder(datadir,\n",
    "                    transform=test_transforms)\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "    train_idx, test_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "    trainloader = torch.utils.data.DataLoader(train_data,\n",
    "                   sampler=train_sampler, batch_size=8)\n",
    "    testloader = torch.utils.data.DataLoader(test_data,\n",
    "                   sampler=test_sampler, batch_size=8)\n",
    "    return trainloader, testloader\n",
    "trainloader, testloader = load_split_train_test(data_dir, .25)\n",
    "print(trainloader.dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "num_frts = model_ft.classifier[1].in_features #mobilenet\n",
    "model_ft.classifier[1] = nn.Linear(num_frts, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer_ft = optim.Adagrad(model_ft.parameters(), lr=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2(\n",
      "  (features): Sequential(\n",
      "    (0): ConvBNReLU(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (16): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (17): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (18): ConvBNReLU(\n",
      "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=1280, out_features=2, bias=True)\n",
      "  )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10.. Train loss: 0.638.. Test loss: 0.398.. Test accuracy: 0.813\n",
      "Epoch 1/10.. Train loss: 0.563.. Test loss: 0.314.. Test accuracy: 0.867\n",
      "Epoch 1/10.. Train loss: 0.527.. Test loss: 0.245.. Test accuracy: 0.905\n",
      "Epoch 1/10.. Train loss: 0.474.. Test loss: 0.240.. Test accuracy: 0.900\n",
      "Epoch 1/10.. Train loss: 0.275.. Test loss: 0.228.. Test accuracy: 0.907\n",
      "Epoch 1/10.. Train loss: 0.415.. Test loss: 0.146.. Test accuracy: 0.942\n",
      "Epoch 1/10.. Train loss: 0.444.. Test loss: 0.135.. Test accuracy: 0.954\n",
      "Epoch 1/10.. Train loss: 0.413.. Test loss: 0.157.. Test accuracy: 0.947\n",
      "Epoch 1/10.. Train loss: 0.210.. Test loss: 0.105.. Test accuracy: 0.965\n",
      "Epoch 1/10.. Train loss: 0.315.. Test loss: 0.131.. Test accuracy: 0.938\n",
      "Epoch 1/10.. Train loss: 0.334.. Test loss: 0.089.. Test accuracy: 0.967\n",
      "Epoch 1/10.. Train loss: 0.366.. Test loss: 0.097.. Test accuracy: 0.974\n",
      "Epoch 1/10.. Train loss: 0.351.. Test loss: 0.094.. Test accuracy: 0.965\n",
      "Epoch 1/10.. Train loss: 0.329.. Test loss: 0.098.. Test accuracy: 0.968\n",
      "Epoch 1/10.. Train loss: 0.220.. Test loss: 0.087.. Test accuracy: 0.969\n",
      "Epoch 1/10.. Train loss: 0.288.. Test loss: 0.085.. Test accuracy: 0.977\n",
      "Epoch 1/10.. Train loss: 0.356.. Test loss: 0.077.. Test accuracy: 0.974\n",
      "Epoch 1/10.. Train loss: 0.425.. Test loss: 0.100.. Test accuracy: 0.964\n",
      "Epoch 1/10.. Train loss: 0.283.. Test loss: 0.093.. Test accuracy: 0.965\n",
      "Epoch 1/10.. Train loss: 0.222.. Test loss: 0.095.. Test accuracy: 0.962\n",
      "Epoch 1/10.. Train loss: 0.286.. Test loss: 0.091.. Test accuracy: 0.969\n",
      "Epoch 1/10.. Train loss: 0.265.. Test loss: 0.083.. Test accuracy: 0.970\n",
      "Epoch 1/10.. Train loss: 0.274.. Test loss: 0.083.. Test accuracy: 0.973\n",
      "Epoch 1/10.. Train loss: 0.282.. Test loss: 0.083.. Test accuracy: 0.979\n",
      "Epoch 1/10.. Train loss: 0.254.. Test loss: 0.081.. Test accuracy: 0.968\n",
      "Epoch 1/10.. Train loss: 0.339.. Test loss: 0.077.. Test accuracy: 0.975\n",
      "Epoch 1/10.. Train loss: 0.281.. Test loss: 0.085.. Test accuracy: 0.975\n",
      "Epoch 1/10.. Train loss: 0.123.. Test loss: 0.085.. Test accuracy: 0.971\n",
      "Epoch 1/10.. Train loss: 0.222.. Test loss: 0.076.. Test accuracy: 0.976\n",
      "Epoch 1/10.. Train loss: 0.247.. Test loss: 0.068.. Test accuracy: 0.974\n",
      "Epoch 1/10.. Train loss: 0.373.. Test loss: 0.079.. Test accuracy: 0.971\n",
      "Epoch 1/10.. Train loss: 0.187.. Test loss: 0.075.. Test accuracy: 0.981\n",
      "Epoch 1/10.. Train loss: 0.253.. Test loss: 0.065.. Test accuracy: 0.982\n",
      "Epoch 1/10.. Train loss: 0.316.. Test loss: 0.071.. Test accuracy: 0.977\n",
      "Epoch 1/10.. Train loss: 0.290.. Test loss: 0.071.. Test accuracy: 0.973\n",
      "Epoch 1/10.. Train loss: 0.204.. Test loss: 0.075.. Test accuracy: 0.974\n",
      "Epoch 1/10.. Train loss: 0.291.. Test loss: 0.061.. Test accuracy: 0.983\n",
      "Epoch 1/10.. Train loss: 0.267.. Test loss: 0.067.. Test accuracy: 0.981\n",
      "Epoch 1/10.. Train loss: 0.240.. Test loss: 0.070.. Test accuracy: 0.976\n",
      "Epoch 1/10.. Train loss: 0.155.. Test loss: 0.048.. Test accuracy: 0.984\n",
      "Epoch 1/10.. Train loss: 0.173.. Test loss: 0.051.. Test accuracy: 0.983\n",
      "Epoch 1/10.. Train loss: 0.139.. Test loss: 0.057.. Test accuracy: 0.979\n",
      "Epoch 1/10.. Train loss: 0.201.. Test loss: 0.076.. Test accuracy: 0.972\n",
      "Epoch 1/10.. Train loss: 0.374.. Test loss: 0.071.. Test accuracy: 0.975\n",
      "Epoch 1/10.. Train loss: 0.306.. Test loss: 0.066.. Test accuracy: 0.974\n",
      "Epoch 1/10.. Train loss: 0.164.. Test loss: 0.055.. Test accuracy: 0.986\n",
      "Epoch 1/10.. Train loss: 0.187.. Test loss: 0.070.. Test accuracy: 0.972\n",
      "Epoch 1/10.. Train loss: 0.256.. Test loss: 0.067.. Test accuracy: 0.975\n",
      "Epoch 1/10.. Train loss: 0.218.. Test loss: 0.072.. Test accuracy: 0.976\n",
      "Epoch 2/10.. Train loss: 0.187.. Test loss: 0.067.. Test accuracy: 0.979\n",
      "Epoch 2/10.. Train loss: 0.154.. Test loss: 0.067.. Test accuracy: 0.974\n",
      "Epoch 2/10.. Train loss: 0.130.. Test loss: 0.052.. Test accuracy: 0.983\n",
      "Epoch 2/10.. Train loss: 0.295.. Test loss: 0.061.. Test accuracy: 0.984\n",
      "Epoch 2/10.. Train loss: 0.333.. Test loss: 0.067.. Test accuracy: 0.978\n",
      "Epoch 2/10.. Train loss: 0.116.. Test loss: 0.055.. Test accuracy: 0.980\n",
      "Epoch 2/10.. Train loss: 0.218.. Test loss: 0.060.. Test accuracy: 0.980\n",
      "Epoch 2/10.. Train loss: 0.263.. Test loss: 0.056.. Test accuracy: 0.983\n",
      "Epoch 2/10.. Train loss: 0.268.. Test loss: 0.061.. Test accuracy: 0.977\n",
      "Epoch 2/10.. Train loss: 0.151.. Test loss: 0.060.. Test accuracy: 0.984\n",
      "Epoch 2/10.. Train loss: 0.141.. Test loss: 0.053.. Test accuracy: 0.985\n",
      "Epoch 2/10.. Train loss: 0.222.. Test loss: 0.070.. Test accuracy: 0.975\n",
      "Epoch 2/10.. Train loss: 0.234.. Test loss: 0.050.. Test accuracy: 0.989\n",
      "Epoch 2/10.. Train loss: 0.168.. Test loss: 0.053.. Test accuracy: 0.981\n",
      "Epoch 2/10.. Train loss: 0.122.. Test loss: 0.050.. Test accuracy: 0.985\n",
      "Epoch 2/10.. Train loss: 0.196.. Test loss: 0.052.. Test accuracy: 0.982\n",
      "Epoch 2/10.. Train loss: 0.200.. Test loss: 0.043.. Test accuracy: 0.989\n",
      "Epoch 2/10.. Train loss: 0.156.. Test loss: 0.049.. Test accuracy: 0.985\n",
      "Epoch 2/10.. Train loss: 0.250.. Test loss: 0.052.. Test accuracy: 0.981\n",
      "Epoch 2/10.. Train loss: 0.232.. Test loss: 0.066.. Test accuracy: 0.976\n",
      "Epoch 2/10.. Train loss: 0.360.. Test loss: 0.067.. Test accuracy: 0.976\n",
      "Epoch 2/10.. Train loss: 0.181.. Test loss: 0.052.. Test accuracy: 0.981\n",
      "Epoch 2/10.. Train loss: 0.187.. Test loss: 0.048.. Test accuracy: 0.981\n",
      "Epoch 2/10.. Train loss: 0.200.. Test loss: 0.046.. Test accuracy: 0.986\n",
      "Epoch 2/10.. Train loss: 0.094.. Test loss: 0.050.. Test accuracy: 0.983\n",
      "Epoch 2/10.. Train loss: 0.126.. Test loss: 0.053.. Test accuracy: 0.977\n",
      "Epoch 2/10.. Train loss: 0.232.. Test loss: 0.042.. Test accuracy: 0.986\n",
      "Epoch 2/10.. Train loss: 0.134.. Test loss: 0.042.. Test accuracy: 0.985\n",
      "Epoch 2/10.. Train loss: 0.200.. Test loss: 0.052.. Test accuracy: 0.980\n",
      "Epoch 2/10.. Train loss: 0.179.. Test loss: 0.056.. Test accuracy: 0.978\n",
      "Epoch 2/10.. Train loss: 0.284.. Test loss: 0.052.. Test accuracy: 0.984\n",
      "Epoch 2/10.. Train loss: 0.148.. Test loss: 0.046.. Test accuracy: 0.988\n",
      "Epoch 2/10.. Train loss: 0.264.. Test loss: 0.063.. Test accuracy: 0.978\n",
      "Epoch 2/10.. Train loss: 0.295.. Test loss: 0.068.. Test accuracy: 0.974\n",
      "Epoch 2/10.. Train loss: 0.296.. Test loss: 0.044.. Test accuracy: 0.986\n",
      "Epoch 2/10.. Train loss: 0.291.. Test loss: 0.052.. Test accuracy: 0.983\n",
      "Epoch 2/10.. Train loss: 0.264.. Test loss: 0.072.. Test accuracy: 0.970\n",
      "Epoch 2/10.. Train loss: 0.154.. Test loss: 0.052.. Test accuracy: 0.983\n",
      "Epoch 2/10.. Train loss: 0.205.. Test loss: 0.045.. Test accuracy: 0.986\n",
      "Epoch 2/10.. Train loss: 0.273.. Test loss: 0.059.. Test accuracy: 0.982\n",
      "Epoch 2/10.. Train loss: 0.333.. Test loss: 0.055.. Test accuracy: 0.977\n",
      "Epoch 2/10.. Train loss: 0.138.. Test loss: 0.048.. Test accuracy: 0.988\n",
      "Epoch 2/10.. Train loss: 0.186.. Test loss: 0.058.. Test accuracy: 0.984\n",
      "Epoch 2/10.. Train loss: 0.125.. Test loss: 0.054.. Test accuracy: 0.987\n",
      "Epoch 2/10.. Train loss: 0.219.. Test loss: 0.053.. Test accuracy: 0.985\n",
      "Epoch 2/10.. Train loss: 0.158.. Test loss: 0.055.. Test accuracy: 0.981\n",
      "Epoch 2/10.. Train loss: 0.183.. Test loss: 0.039.. Test accuracy: 0.992\n",
      "Epoch 2/10.. Train loss: 0.308.. Test loss: 0.046.. Test accuracy: 0.984\n",
      "Epoch 2/10.. Train loss: 0.176.. Test loss: 0.056.. Test accuracy: 0.980\n",
      "Epoch 2/10.. Train loss: 0.306.. Test loss: 0.060.. Test accuracy: 0.974\n",
      "Epoch 3/10.. Train loss: 0.502.. Test loss: 0.061.. Test accuracy: 0.979\n",
      "Epoch 3/10.. Train loss: 0.180.. Test loss: 0.054.. Test accuracy: 0.982\n",
      "Epoch 3/10.. Train loss: 0.183.. Test loss: 0.050.. Test accuracy: 0.986\n",
      "Epoch 3/10.. Train loss: 0.266.. Test loss: 0.046.. Test accuracy: 0.989\n",
      "Epoch 3/10.. Train loss: 0.157.. Test loss: 0.057.. Test accuracy: 0.981\n",
      "Epoch 3/10.. Train loss: 0.103.. Test loss: 0.047.. Test accuracy: 0.986\n",
      "Epoch 3/10.. Train loss: 0.165.. Test loss: 0.052.. Test accuracy: 0.982\n",
      "Epoch 3/10.. Train loss: 0.139.. Test loss: 0.043.. Test accuracy: 0.988\n",
      "Epoch 3/10.. Train loss: 0.199.. Test loss: 0.041.. Test accuracy: 0.987\n",
      "Epoch 3/10.. Train loss: 0.244.. Test loss: 0.043.. Test accuracy: 0.986\n",
      "Epoch 3/10.. Train loss: 0.201.. Test loss: 0.042.. Test accuracy: 0.986\n",
      "Epoch 3/10.. Train loss: 0.115.. Test loss: 0.038.. Test accuracy: 0.988\n",
      "Epoch 3/10.. Train loss: 0.282.. Test loss: 0.051.. Test accuracy: 0.984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10.. Train loss: 0.272.. Test loss: 0.038.. Test accuracy: 0.987\n",
      "Epoch 3/10.. Train loss: 0.196.. Test loss: 0.042.. Test accuracy: 0.991\n",
      "Epoch 3/10.. Train loss: 0.228.. Test loss: 0.043.. Test accuracy: 0.985\n",
      "Epoch 3/10.. Train loss: 0.167.. Test loss: 0.047.. Test accuracy: 0.982\n",
      "Epoch 3/10.. Train loss: 0.128.. Test loss: 0.042.. Test accuracy: 0.984\n",
      "Epoch 3/10.. Train loss: 0.212.. Test loss: 0.040.. Test accuracy: 0.986\n",
      "Epoch 3/10.. Train loss: 0.161.. Test loss: 0.045.. Test accuracy: 0.984\n",
      "Epoch 3/10.. Train loss: 0.285.. Test loss: 0.048.. Test accuracy: 0.986\n",
      "Epoch 3/10.. Train loss: 0.157.. Test loss: 0.046.. Test accuracy: 0.985\n",
      "Epoch 3/10.. Train loss: 0.214.. Test loss: 0.043.. Test accuracy: 0.984\n",
      "Epoch 3/10.. Train loss: 0.167.. Test loss: 0.036.. Test accuracy: 0.989\n",
      "Epoch 3/10.. Train loss: 0.266.. Test loss: 0.045.. Test accuracy: 0.985\n",
      "Epoch 3/10.. Train loss: 0.174.. Test loss: 0.038.. Test accuracy: 0.988\n",
      "Epoch 3/10.. Train loss: 0.253.. Test loss: 0.043.. Test accuracy: 0.988\n",
      "Epoch 3/10.. Train loss: 0.183.. Test loss: 0.041.. Test accuracy: 0.985\n",
      "Epoch 3/10.. Train loss: 0.140.. Test loss: 0.044.. Test accuracy: 0.986\n",
      "Epoch 3/10.. Train loss: 0.202.. Test loss: 0.044.. Test accuracy: 0.990\n",
      "Epoch 3/10.. Train loss: 0.159.. Test loss: 0.056.. Test accuracy: 0.981\n",
      "Epoch 3/10.. Train loss: 0.124.. Test loss: 0.051.. Test accuracy: 0.980\n",
      "Epoch 3/10.. Train loss: 0.117.. Test loss: 0.034.. Test accuracy: 0.990\n",
      "Epoch 3/10.. Train loss: 0.184.. Test loss: 0.044.. Test accuracy: 0.986\n",
      "Epoch 3/10.. Train loss: 0.138.. Test loss: 0.035.. Test accuracy: 0.992\n",
      "Epoch 3/10.. Train loss: 0.142.. Test loss: 0.037.. Test accuracy: 0.988\n",
      "Epoch 3/10.. Train loss: 0.256.. Test loss: 0.039.. Test accuracy: 0.986\n",
      "Epoch 3/10.. Train loss: 0.196.. Test loss: 0.035.. Test accuracy: 0.989\n",
      "Epoch 3/10.. Train loss: 0.125.. Test loss: 0.035.. Test accuracy: 0.992\n",
      "Epoch 3/10.. Train loss: 0.100.. Test loss: 0.034.. Test accuracy: 0.989\n",
      "Epoch 3/10.. Train loss: 0.095.. Test loss: 0.035.. Test accuracy: 0.991\n",
      "Epoch 3/10.. Train loss: 0.098.. Test loss: 0.034.. Test accuracy: 0.988\n",
      "Epoch 3/10.. Train loss: 0.221.. Test loss: 0.036.. Test accuracy: 0.992\n",
      "Epoch 3/10.. Train loss: 0.127.. Test loss: 0.048.. Test accuracy: 0.981\n",
      "Epoch 3/10.. Train loss: 0.100.. Test loss: 0.039.. Test accuracy: 0.989\n",
      "Epoch 3/10.. Train loss: 0.103.. Test loss: 0.039.. Test accuracy: 0.987\n",
      "Epoch 3/10.. Train loss: 0.365.. Test loss: 0.043.. Test accuracy: 0.988\n",
      "Epoch 3/10.. Train loss: 0.183.. Test loss: 0.042.. Test accuracy: 0.987\n",
      "Epoch 3/10.. Train loss: 0.130.. Test loss: 0.040.. Test accuracy: 0.989\n",
      "Epoch 3/10.. Train loss: 0.153.. Test loss: 0.031.. Test accuracy: 0.990\n",
      "Epoch 4/10.. Train loss: 0.138.. Test loss: 0.035.. Test accuracy: 0.994\n",
      "Epoch 4/10.. Train loss: 0.162.. Test loss: 0.044.. Test accuracy: 0.986\n",
      "Epoch 4/10.. Train loss: 0.139.. Test loss: 0.030.. Test accuracy: 0.987\n",
      "Epoch 4/10.. Train loss: 0.175.. Test loss: 0.042.. Test accuracy: 0.985\n",
      "Epoch 4/10.. Train loss: 0.336.. Test loss: 0.035.. Test accuracy: 0.986\n",
      "Epoch 4/10.. Train loss: 0.131.. Test loss: 0.036.. Test accuracy: 0.992\n",
      "Epoch 4/10.. Train loss: 0.182.. Test loss: 0.034.. Test accuracy: 0.989\n",
      "Epoch 4/10.. Train loss: 0.195.. Test loss: 0.045.. Test accuracy: 0.983\n",
      "Epoch 4/10.. Train loss: 0.191.. Test loss: 0.037.. Test accuracy: 0.988\n",
      "Epoch 4/10.. Train loss: 0.099.. Test loss: 0.044.. Test accuracy: 0.986\n",
      "Epoch 4/10.. Train loss: 0.208.. Test loss: 0.044.. Test accuracy: 0.986\n",
      "Epoch 4/10.. Train loss: 0.128.. Test loss: 0.043.. Test accuracy: 0.983\n",
      "Epoch 4/10.. Train loss: 0.312.. Test loss: 0.037.. Test accuracy: 0.986\n",
      "Epoch 4/10.. Train loss: 0.182.. Test loss: 0.034.. Test accuracy: 0.989\n",
      "Epoch 4/10.. Train loss: 0.142.. Test loss: 0.041.. Test accuracy: 0.986\n",
      "Epoch 4/10.. Train loss: 0.158.. Test loss: 0.034.. Test accuracy: 0.988\n",
      "Epoch 4/10.. Train loss: 0.172.. Test loss: 0.045.. Test accuracy: 0.983\n",
      "Epoch 4/10.. Train loss: 0.205.. Test loss: 0.047.. Test accuracy: 0.983\n",
      "Epoch 4/10.. Train loss: 0.222.. Test loss: 0.039.. Test accuracy: 0.984\n",
      "Epoch 4/10.. Train loss: 0.132.. Test loss: 0.043.. Test accuracy: 0.986\n",
      "Epoch 4/10.. Train loss: 0.134.. Test loss: 0.038.. Test accuracy: 0.989\n",
      "Epoch 4/10.. Train loss: 0.238.. Test loss: 0.033.. Test accuracy: 0.988\n",
      "Epoch 4/10.. Train loss: 0.140.. Test loss: 0.033.. Test accuracy: 0.988\n",
      "Epoch 4/10.. Train loss: 0.159.. Test loss: 0.041.. Test accuracy: 0.985\n",
      "Epoch 4/10.. Train loss: 0.252.. Test loss: 0.037.. Test accuracy: 0.989\n",
      "Epoch 4/10.. Train loss: 0.211.. Test loss: 0.039.. Test accuracy: 0.986\n",
      "Epoch 4/10.. Train loss: 0.074.. Test loss: 0.039.. Test accuracy: 0.986\n",
      "Epoch 4/10.. Train loss: 0.191.. Test loss: 0.036.. Test accuracy: 0.991\n",
      "Epoch 4/10.. Train loss: 0.091.. Test loss: 0.037.. Test accuracy: 0.986\n",
      "Epoch 4/10.. Train loss: 0.187.. Test loss: 0.046.. Test accuracy: 0.980\n",
      "Epoch 4/10.. Train loss: 0.110.. Test loss: 0.038.. Test accuracy: 0.988\n",
      "Epoch 4/10.. Train loss: 0.117.. Test loss: 0.040.. Test accuracy: 0.989\n",
      "Epoch 4/10.. Train loss: 0.092.. Test loss: 0.035.. Test accuracy: 0.987\n",
      "Epoch 4/10.. Train loss: 0.417.. Test loss: 0.035.. Test accuracy: 0.988\n",
      "Epoch 4/10.. Train loss: 0.118.. Test loss: 0.032.. Test accuracy: 0.992\n",
      "Epoch 4/10.. Train loss: 0.127.. Test loss: 0.037.. Test accuracy: 0.990\n",
      "Epoch 4/10.. Train loss: 0.208.. Test loss: 0.036.. Test accuracy: 0.987\n",
      "Epoch 4/10.. Train loss: 0.140.. Test loss: 0.038.. Test accuracy: 0.987\n",
      "Epoch 4/10.. Train loss: 0.093.. Test loss: 0.042.. Test accuracy: 0.983\n",
      "Epoch 4/10.. Train loss: 0.171.. Test loss: 0.036.. Test accuracy: 0.988\n",
      "Epoch 4/10.. Train loss: 0.215.. Test loss: 0.034.. Test accuracy: 0.989\n",
      "Epoch 4/10.. Train loss: 0.148.. Test loss: 0.037.. Test accuracy: 0.986\n",
      "Epoch 4/10.. Train loss: 0.150.. Test loss: 0.030.. Test accuracy: 0.993\n",
      "Epoch 4/10.. Train loss: 0.114.. Test loss: 0.033.. Test accuracy: 0.988\n",
      "Epoch 4/10.. Train loss: 0.136.. Test loss: 0.035.. Test accuracy: 0.989\n",
      "Epoch 4/10.. Train loss: 0.089.. Test loss: 0.032.. Test accuracy: 0.991\n",
      "Epoch 4/10.. Train loss: 0.278.. Test loss: 0.039.. Test accuracy: 0.986\n",
      "Epoch 4/10.. Train loss: 0.151.. Test loss: 0.040.. Test accuracy: 0.987\n",
      "Epoch 4/10.. Train loss: 0.080.. Test loss: 0.042.. Test accuracy: 0.983\n",
      "Epoch 5/10.. Train loss: 0.249.. Test loss: 0.026.. Test accuracy: 0.991\n",
      "Epoch 5/10.. Train loss: 0.168.. Test loss: 0.037.. Test accuracy: 0.985\n",
      "Epoch 5/10.. Train loss: 0.180.. Test loss: 0.036.. Test accuracy: 0.989\n",
      "Epoch 5/10.. Train loss: 0.087.. Test loss: 0.037.. Test accuracy: 0.991\n",
      "Epoch 5/10.. Train loss: 0.282.. Test loss: 0.037.. Test accuracy: 0.986\n",
      "Epoch 5/10.. Train loss: 0.150.. Test loss: 0.024.. Test accuracy: 0.994\n",
      "Epoch 5/10.. Train loss: 0.129.. Test loss: 0.041.. Test accuracy: 0.986\n",
      "Epoch 5/10.. Train loss: 0.126.. Test loss: 0.041.. Test accuracy: 0.983\n",
      "Epoch 5/10.. Train loss: 0.245.. Test loss: 0.049.. Test accuracy: 0.982\n",
      "Epoch 5/10.. Train loss: 0.099.. Test loss: 0.028.. Test accuracy: 0.991\n",
      "Epoch 5/10.. Train loss: 0.138.. Test loss: 0.034.. Test accuracy: 0.989\n",
      "Epoch 5/10.. Train loss: 0.176.. Test loss: 0.036.. Test accuracy: 0.988\n",
      "Epoch 5/10.. Train loss: 0.247.. Test loss: 0.042.. Test accuracy: 0.984\n",
      "Epoch 5/10.. Train loss: 0.321.. Test loss: 0.036.. Test accuracy: 0.990\n",
      "Epoch 5/10.. Train loss: 0.210.. Test loss: 0.036.. Test accuracy: 0.987\n",
      "Epoch 5/10.. Train loss: 0.116.. Test loss: 0.049.. Test accuracy: 0.986\n",
      "Epoch 5/10.. Train loss: 0.141.. Test loss: 0.042.. Test accuracy: 0.984\n",
      "Epoch 5/10.. Train loss: 0.107.. Test loss: 0.039.. Test accuracy: 0.988\n",
      "Epoch 5/10.. Train loss: 0.146.. Test loss: 0.035.. Test accuracy: 0.990\n",
      "Epoch 5/10.. Train loss: 0.119.. Test loss: 0.034.. Test accuracy: 0.988\n",
      "Epoch 5/10.. Train loss: 0.130.. Test loss: 0.041.. Test accuracy: 0.987\n",
      "Epoch 5/10.. Train loss: 0.119.. Test loss: 0.042.. Test accuracy: 0.989\n",
      "Epoch 5/10.. Train loss: 0.099.. Test loss: 0.041.. Test accuracy: 0.988\n",
      "Epoch 5/10.. Train loss: 0.088.. Test loss: 0.039.. Test accuracy: 0.988\n",
      "Epoch 5/10.. Train loss: 0.258.. Test loss: 0.036.. Test accuracy: 0.992\n",
      "Epoch 5/10.. Train loss: 0.129.. Test loss: 0.026.. Test accuracy: 0.992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10.. Train loss: 0.203.. Test loss: 0.037.. Test accuracy: 0.988\n",
      "Epoch 5/10.. Train loss: 0.148.. Test loss: 0.039.. Test accuracy: 0.985\n",
      "Epoch 5/10.. Train loss: 0.134.. Test loss: 0.037.. Test accuracy: 0.990\n",
      "Epoch 5/10.. Train loss: 0.160.. Test loss: 0.034.. Test accuracy: 0.992\n",
      "Epoch 5/10.. Train loss: 0.140.. Test loss: 0.034.. Test accuracy: 0.987\n",
      "Epoch 5/10.. Train loss: 0.129.. Test loss: 0.039.. Test accuracy: 0.987\n",
      "Epoch 5/10.. Train loss: 0.200.. Test loss: 0.034.. Test accuracy: 0.991\n",
      "Epoch 5/10.. Train loss: 0.176.. Test loss: 0.034.. Test accuracy: 0.992\n",
      "Epoch 5/10.. Train loss: 0.313.. Test loss: 0.040.. Test accuracy: 0.989\n",
      "Epoch 5/10.. Train loss: 0.083.. Test loss: 0.034.. Test accuracy: 0.989\n",
      "Epoch 5/10.. Train loss: 0.248.. Test loss: 0.035.. Test accuracy: 0.991\n",
      "Epoch 5/10.. Train loss: 0.146.. Test loss: 0.039.. Test accuracy: 0.991\n",
      "Epoch 5/10.. Train loss: 0.141.. Test loss: 0.036.. Test accuracy: 0.987\n",
      "Epoch 5/10.. Train loss: 0.147.. Test loss: 0.040.. Test accuracy: 0.988\n",
      "Epoch 5/10.. Train loss: 0.169.. Test loss: 0.037.. Test accuracy: 0.987\n",
      "Epoch 5/10.. Train loss: 0.181.. Test loss: 0.036.. Test accuracy: 0.989\n",
      "Epoch 5/10.. Train loss: 0.118.. Test loss: 0.036.. Test accuracy: 0.989\n",
      "Epoch 5/10.. Train loss: 0.225.. Test loss: 0.032.. Test accuracy: 0.992\n",
      "Epoch 5/10.. Train loss: 0.127.. Test loss: 0.025.. Test accuracy: 0.996\n",
      "Epoch 5/10.. Train loss: 0.158.. Test loss: 0.038.. Test accuracy: 0.984\n",
      "Epoch 5/10.. Train loss: 0.137.. Test loss: 0.040.. Test accuracy: 0.985\n",
      "Epoch 5/10.. Train loss: 0.126.. Test loss: 0.033.. Test accuracy: 0.990\n",
      "Epoch 5/10.. Train loss: 0.130.. Test loss: 0.030.. Test accuracy: 0.990\n",
      "Epoch 5/10.. Train loss: 0.147.. Test loss: 0.034.. Test accuracy: 0.992\n",
      "Epoch 6/10.. Train loss: 0.101.. Test loss: 0.040.. Test accuracy: 0.989\n",
      "Epoch 6/10.. Train loss: 0.208.. Test loss: 0.035.. Test accuracy: 0.988\n",
      "Epoch 6/10.. Train loss: 0.065.. Test loss: 0.038.. Test accuracy: 0.989\n",
      "Epoch 6/10.. Train loss: 0.107.. Test loss: 0.036.. Test accuracy: 0.988\n",
      "Epoch 6/10.. Train loss: 0.166.. Test loss: 0.032.. Test accuracy: 0.992\n",
      "Epoch 6/10.. Train loss: 0.185.. Test loss: 0.041.. Test accuracy: 0.990\n",
      "Epoch 6/10.. Train loss: 0.140.. Test loss: 0.036.. Test accuracy: 0.992\n",
      "Epoch 6/10.. Train loss: 0.146.. Test loss: 0.040.. Test accuracy: 0.986\n",
      "Epoch 6/10.. Train loss: 0.088.. Test loss: 0.037.. Test accuracy: 0.988\n",
      "Epoch 6/10.. Train loss: 0.158.. Test loss: 0.035.. Test accuracy: 0.987\n",
      "Epoch 6/10.. Train loss: 0.146.. Test loss: 0.034.. Test accuracy: 0.988\n",
      "Epoch 6/10.. Train loss: 0.101.. Test loss: 0.036.. Test accuracy: 0.990\n",
      "Epoch 6/10.. Train loss: 0.143.. Test loss: 0.038.. Test accuracy: 0.988\n",
      "Epoch 6/10.. Train loss: 0.143.. Test loss: 0.031.. Test accuracy: 0.994\n",
      "Epoch 6/10.. Train loss: 0.099.. Test loss: 0.028.. Test accuracy: 0.993\n",
      "Epoch 6/10.. Train loss: 0.123.. Test loss: 0.029.. Test accuracy: 0.991\n",
      "Epoch 6/10.. Train loss: 0.137.. Test loss: 0.033.. Test accuracy: 0.989\n",
      "Epoch 6/10.. Train loss: 0.171.. Test loss: 0.034.. Test accuracy: 0.987\n",
      "Epoch 6/10.. Train loss: 0.138.. Test loss: 0.026.. Test accuracy: 0.993\n",
      "Epoch 6/10.. Train loss: 0.117.. Test loss: 0.034.. Test accuracy: 0.988\n",
      "Epoch 6/10.. Train loss: 0.139.. Test loss: 0.034.. Test accuracy: 0.989\n",
      "Epoch 6/10.. Train loss: 0.099.. Test loss: 0.030.. Test accuracy: 0.993\n",
      "Epoch 6/10.. Train loss: 0.139.. Test loss: 0.024.. Test accuracy: 0.993\n",
      "Epoch 6/10.. Train loss: 0.177.. Test loss: 0.036.. Test accuracy: 0.987\n",
      "Epoch 6/10.. Train loss: 0.092.. Test loss: 0.037.. Test accuracy: 0.986\n",
      "Epoch 6/10.. Train loss: 0.166.. Test loss: 0.031.. Test accuracy: 0.992\n",
      "Epoch 6/10.. Train loss: 0.133.. Test loss: 0.036.. Test accuracy: 0.987\n",
      "Epoch 6/10.. Train loss: 0.343.. Test loss: 0.035.. Test accuracy: 0.991\n",
      "Epoch 6/10.. Train loss: 0.130.. Test loss: 0.034.. Test accuracy: 0.990\n",
      "Epoch 6/10.. Train loss: 0.122.. Test loss: 0.034.. Test accuracy: 0.990\n",
      "Epoch 6/10.. Train loss: 0.173.. Test loss: 0.032.. Test accuracy: 0.988\n",
      "Epoch 6/10.. Train loss: 0.101.. Test loss: 0.037.. Test accuracy: 0.988\n",
      "Epoch 6/10.. Train loss: 0.212.. Test loss: 0.035.. Test accuracy: 0.989\n",
      "Epoch 6/10.. Train loss: 0.130.. Test loss: 0.040.. Test accuracy: 0.991\n",
      "Epoch 6/10.. Train loss: 0.076.. Test loss: 0.036.. Test accuracy: 0.990\n",
      "Epoch 6/10.. Train loss: 0.167.. Test loss: 0.038.. Test accuracy: 0.987\n",
      "Epoch 6/10.. Train loss: 0.142.. Test loss: 0.039.. Test accuracy: 0.986\n",
      "Epoch 6/10.. Train loss: 0.088.. Test loss: 0.036.. Test accuracy: 0.986\n",
      "Epoch 6/10.. Train loss: 0.228.. Test loss: 0.039.. Test accuracy: 0.989\n",
      "Epoch 6/10.. Train loss: 0.124.. Test loss: 0.030.. Test accuracy: 0.990\n",
      "Epoch 6/10.. Train loss: 0.305.. Test loss: 0.038.. Test accuracy: 0.986\n",
      "Epoch 6/10.. Train loss: 0.078.. Test loss: 0.036.. Test accuracy: 0.989\n",
      "Epoch 6/10.. Train loss: 0.166.. Test loss: 0.033.. Test accuracy: 0.991\n",
      "Epoch 6/10.. Train loss: 0.187.. Test loss: 0.035.. Test accuracy: 0.991\n",
      "Epoch 6/10.. Train loss: 0.159.. Test loss: 0.031.. Test accuracy: 0.991\n",
      "Epoch 6/10.. Train loss: 0.184.. Test loss: 0.031.. Test accuracy: 0.988\n",
      "Epoch 6/10.. Train loss: 0.110.. Test loss: 0.028.. Test accuracy: 0.992\n",
      "Epoch 6/10.. Train loss: 0.166.. Test loss: 0.038.. Test accuracy: 0.983\n",
      "Epoch 6/10.. Train loss: 0.130.. Test loss: 0.037.. Test accuracy: 0.988\n",
      "Epoch 6/10.. Train loss: 0.202.. Test loss: 0.037.. Test accuracy: 0.989\n",
      "Epoch 7/10.. Train loss: 0.095.. Test loss: 0.027.. Test accuracy: 0.989\n",
      "Epoch 7/10.. Train loss: 0.214.. Test loss: 0.032.. Test accuracy: 0.993\n",
      "Epoch 7/10.. Train loss: 0.158.. Test loss: 0.034.. Test accuracy: 0.989\n",
      "Epoch 7/10.. Train loss: 0.092.. Test loss: 0.041.. Test accuracy: 0.987\n",
      "Epoch 7/10.. Train loss: 0.137.. Test loss: 0.032.. Test accuracy: 0.992\n",
      "Epoch 7/10.. Train loss: 0.146.. Test loss: 0.043.. Test accuracy: 0.986\n",
      "Epoch 7/10.. Train loss: 0.119.. Test loss: 0.027.. Test accuracy: 0.993\n",
      "Epoch 7/10.. Train loss: 0.100.. Test loss: 0.030.. Test accuracy: 0.993\n",
      "Epoch 7/10.. Train loss: 0.112.. Test loss: 0.026.. Test accuracy: 0.995\n",
      "Epoch 7/10.. Train loss: 0.084.. Test loss: 0.032.. Test accuracy: 0.989\n",
      "Epoch 7/10.. Train loss: 0.097.. Test loss: 0.039.. Test accuracy: 0.984\n",
      "Epoch 7/10.. Train loss: 0.093.. Test loss: 0.032.. Test accuracy: 0.992\n",
      "Epoch 7/10.. Train loss: 0.175.. Test loss: 0.029.. Test accuracy: 0.992\n",
      "Epoch 7/10.. Train loss: 0.098.. Test loss: 0.036.. Test accuracy: 0.990\n",
      "Epoch 7/10.. Train loss: 0.199.. Test loss: 0.027.. Test accuracy: 0.995\n",
      "Epoch 7/10.. Train loss: 0.086.. Test loss: 0.031.. Test accuracy: 0.990\n",
      "Epoch 7/10.. Train loss: 0.145.. Test loss: 0.034.. Test accuracy: 0.988\n",
      "Epoch 7/10.. Train loss: 0.179.. Test loss: 0.034.. Test accuracy: 0.992\n",
      "Epoch 7/10.. Train loss: 0.092.. Test loss: 0.033.. Test accuracy: 0.989\n",
      "Epoch 7/10.. Train loss: 0.140.. Test loss: 0.037.. Test accuracy: 0.986\n",
      "Epoch 7/10.. Train loss: 0.123.. Test loss: 0.029.. Test accuracy: 0.993\n",
      "Epoch 7/10.. Train loss: 0.094.. Test loss: 0.028.. Test accuracy: 0.989\n",
      "Epoch 7/10.. Train loss: 0.143.. Test loss: 0.030.. Test accuracy: 0.989\n",
      "Epoch 7/10.. Train loss: 0.097.. Test loss: 0.031.. Test accuracy: 0.991\n",
      "Epoch 7/10.. Train loss: 0.157.. Test loss: 0.034.. Test accuracy: 0.984\n",
      "Epoch 7/10.. Train loss: 0.131.. Test loss: 0.035.. Test accuracy: 0.984\n",
      "Epoch 7/10.. Train loss: 0.093.. Test loss: 0.030.. Test accuracy: 0.992\n",
      "Epoch 7/10.. Train loss: 0.081.. Test loss: 0.029.. Test accuracy: 0.994\n",
      "Epoch 7/10.. Train loss: 0.058.. Test loss: 0.029.. Test accuracy: 0.992\n",
      "Epoch 7/10.. Train loss: 0.089.. Test loss: 0.033.. Test accuracy: 0.988\n",
      "Epoch 7/10.. Train loss: 0.085.. Test loss: 0.028.. Test accuracy: 0.990\n",
      "Epoch 7/10.. Train loss: 0.139.. Test loss: 0.035.. Test accuracy: 0.986\n",
      "Epoch 7/10.. Train loss: 0.115.. Test loss: 0.027.. Test accuracy: 0.994\n",
      "Epoch 7/10.. Train loss: 0.124.. Test loss: 0.033.. Test accuracy: 0.992\n",
      "Epoch 7/10.. Train loss: 0.032.. Test loss: 0.032.. Test accuracy: 0.990\n",
      "Epoch 7/10.. Train loss: 0.088.. Test loss: 0.033.. Test accuracy: 0.989\n",
      "Epoch 7/10.. Train loss: 0.217.. Test loss: 0.034.. Test accuracy: 0.990\n",
      "Epoch 7/10.. Train loss: 0.110.. Test loss: 0.028.. Test accuracy: 0.991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10.. Train loss: 0.093.. Test loss: 0.032.. Test accuracy: 0.992\n",
      "Epoch 7/10.. Train loss: 0.130.. Test loss: 0.028.. Test accuracy: 0.992\n",
      "Epoch 7/10.. Train loss: 0.523.. Test loss: 0.030.. Test accuracy: 0.990\n",
      "Epoch 7/10.. Train loss: 0.136.. Test loss: 0.030.. Test accuracy: 0.990\n",
      "Epoch 7/10.. Train loss: 0.102.. Test loss: 0.029.. Test accuracy: 0.993\n",
      "Epoch 7/10.. Train loss: 0.084.. Test loss: 0.031.. Test accuracy: 0.990\n",
      "Epoch 7/10.. Train loss: 0.109.. Test loss: 0.028.. Test accuracy: 0.993\n",
      "Epoch 7/10.. Train loss: 0.167.. Test loss: 0.028.. Test accuracy: 0.993\n",
      "Epoch 7/10.. Train loss: 0.130.. Test loss: 0.029.. Test accuracy: 0.993\n",
      "Epoch 7/10.. Train loss: 0.102.. Test loss: 0.032.. Test accuracy: 0.991\n",
      "Epoch 7/10.. Train loss: 0.079.. Test loss: 0.033.. Test accuracy: 0.992\n",
      "Epoch 8/10.. Train loss: 0.078.. Test loss: 0.032.. Test accuracy: 0.990\n",
      "Epoch 8/10.. Train loss: 0.057.. Test loss: 0.032.. Test accuracy: 0.992\n",
      "Epoch 8/10.. Train loss: 0.197.. Test loss: 0.031.. Test accuracy: 0.989\n",
      "Epoch 8/10.. Train loss: 0.122.. Test loss: 0.032.. Test accuracy: 0.992\n",
      "Epoch 8/10.. Train loss: 0.066.. Test loss: 0.030.. Test accuracy: 0.993\n",
      "Epoch 8/10.. Train loss: 0.174.. Test loss: 0.033.. Test accuracy: 0.989\n",
      "Epoch 8/10.. Train loss: 0.126.. Test loss: 0.035.. Test accuracy: 0.986\n",
      "Epoch 8/10.. Train loss: 0.241.. Test loss: 0.029.. Test accuracy: 0.989\n",
      "Epoch 8/10.. Train loss: 0.100.. Test loss: 0.030.. Test accuracy: 0.991\n",
      "Epoch 8/10.. Train loss: 0.126.. Test loss: 0.034.. Test accuracy: 0.991\n",
      "Epoch 8/10.. Train loss: 0.110.. Test loss: 0.033.. Test accuracy: 0.990\n",
      "Epoch 8/10.. Train loss: 0.166.. Test loss: 0.038.. Test accuracy: 0.986\n",
      "Epoch 8/10.. Train loss: 0.081.. Test loss: 0.036.. Test accuracy: 0.989\n",
      "Epoch 8/10.. Train loss: 0.106.. Test loss: 0.036.. Test accuracy: 0.990\n",
      "Epoch 8/10.. Train loss: 0.134.. Test loss: 0.024.. Test accuracy: 0.992\n",
      "Epoch 8/10.. Train loss: 0.077.. Test loss: 0.028.. Test accuracy: 0.994\n",
      "Epoch 8/10.. Train loss: 0.334.. Test loss: 0.023.. Test accuracy: 0.992\n",
      "Epoch 8/10.. Train loss: 0.130.. Test loss: 0.027.. Test accuracy: 0.994\n",
      "Epoch 8/10.. Train loss: 0.058.. Test loss: 0.039.. Test accuracy: 0.984\n",
      "Epoch 8/10.. Train loss: 0.242.. Test loss: 0.033.. Test accuracy: 0.991\n",
      "Epoch 8/10.. Train loss: 0.157.. Test loss: 0.026.. Test accuracy: 0.990\n",
      "Epoch 8/10.. Train loss: 0.081.. Test loss: 0.037.. Test accuracy: 0.989\n",
      "Epoch 8/10.. Train loss: 0.264.. Test loss: 0.030.. Test accuracy: 0.990\n",
      "Epoch 8/10.. Train loss: 0.127.. Test loss: 0.033.. Test accuracy: 0.989\n",
      "Epoch 8/10.. Train loss: 0.154.. Test loss: 0.029.. Test accuracy: 0.993\n",
      "Epoch 8/10.. Train loss: 0.066.. Test loss: 0.028.. Test accuracy: 0.992\n",
      "Epoch 8/10.. Train loss: 0.131.. Test loss: 0.026.. Test accuracy: 0.992\n",
      "Epoch 8/10.. Train loss: 0.111.. Test loss: 0.032.. Test accuracy: 0.987\n",
      "Epoch 8/10.. Train loss: 0.130.. Test loss: 0.022.. Test accuracy: 0.994\n",
      "Epoch 8/10.. Train loss: 0.113.. Test loss: 0.024.. Test accuracy: 0.995\n",
      "Epoch 8/10.. Train loss: 0.100.. Test loss: 0.031.. Test accuracy: 0.991\n",
      "Epoch 8/10.. Train loss: 0.140.. Test loss: 0.026.. Test accuracy: 0.992\n",
      "Epoch 8/10.. Train loss: 0.088.. Test loss: 0.027.. Test accuracy: 0.991\n",
      "Epoch 8/10.. Train loss: 0.076.. Test loss: 0.028.. Test accuracy: 0.989\n",
      "Epoch 8/10.. Train loss: 0.089.. Test loss: 0.023.. Test accuracy: 0.995\n",
      "Epoch 8/10.. Train loss: 0.183.. Test loss: 0.027.. Test accuracy: 0.992\n",
      "Epoch 8/10.. Train loss: 0.084.. Test loss: 0.027.. Test accuracy: 0.992\n",
      "Epoch 8/10.. Train loss: 0.176.. Test loss: 0.023.. Test accuracy: 0.992\n",
      "Epoch 8/10.. Train loss: 0.135.. Test loss: 0.028.. Test accuracy: 0.992\n",
      "Epoch 8/10.. Train loss: 0.028.. Test loss: 0.031.. Test accuracy: 0.990\n",
      "Epoch 8/10.. Train loss: 0.118.. Test loss: 0.026.. Test accuracy: 0.995\n",
      "Epoch 8/10.. Train loss: 0.122.. Test loss: 0.025.. Test accuracy: 0.994\n",
      "Epoch 8/10.. Train loss: 0.088.. Test loss: 0.030.. Test accuracy: 0.991\n",
      "Epoch 8/10.. Train loss: 0.179.. Test loss: 0.036.. Test accuracy: 0.987\n",
      "Epoch 8/10.. Train loss: 0.153.. Test loss: 0.027.. Test accuracy: 0.992\n",
      "Epoch 8/10.. Train loss: 0.373.. Test loss: 0.022.. Test accuracy: 0.994\n",
      "Epoch 8/10.. Train loss: 0.152.. Test loss: 0.023.. Test accuracy: 0.992\n",
      "Epoch 8/10.. Train loss: 0.117.. Test loss: 0.032.. Test accuracy: 0.989\n",
      "Epoch 8/10.. Train loss: 0.119.. Test loss: 0.033.. Test accuracy: 0.991\n",
      "Epoch 8/10.. Train loss: 0.144.. Test loss: 0.030.. Test accuracy: 0.994\n",
      "Epoch 9/10.. Train loss: 0.082.. Test loss: 0.028.. Test accuracy: 0.992\n",
      "Epoch 9/10.. Train loss: 0.090.. Test loss: 0.033.. Test accuracy: 0.992\n",
      "Epoch 9/10.. Train loss: 0.222.. Test loss: 0.028.. Test accuracy: 0.989\n",
      "Epoch 9/10.. Train loss: 0.089.. Test loss: 0.036.. Test accuracy: 0.992\n",
      "Epoch 9/10.. Train loss: 0.117.. Test loss: 0.024.. Test accuracy: 0.995\n",
      "Epoch 9/10.. Train loss: 0.154.. Test loss: 0.031.. Test accuracy: 0.993\n",
      "Epoch 9/10.. Train loss: 0.074.. Test loss: 0.035.. Test accuracy: 0.987\n",
      "Epoch 9/10.. Train loss: 0.101.. Test loss: 0.030.. Test accuracy: 0.988\n",
      "Epoch 9/10.. Train loss: 0.154.. Test loss: 0.025.. Test accuracy: 0.993\n",
      "Epoch 9/10.. Train loss: 0.075.. Test loss: 0.025.. Test accuracy: 0.993\n",
      "Epoch 9/10.. Train loss: 0.093.. Test loss: 0.029.. Test accuracy: 0.991\n",
      "Epoch 9/10.. Train loss: 0.061.. Test loss: 0.032.. Test accuracy: 0.989\n",
      "Epoch 9/10.. Train loss: 0.114.. Test loss: 0.021.. Test accuracy: 0.996\n",
      "Epoch 9/10.. Train loss: 0.056.. Test loss: 0.028.. Test accuracy: 0.992\n",
      "Epoch 9/10.. Train loss: 0.110.. Test loss: 0.024.. Test accuracy: 0.995\n",
      "Epoch 9/10.. Train loss: 0.079.. Test loss: 0.040.. Test accuracy: 0.990\n",
      "Epoch 9/10.. Train loss: 0.137.. Test loss: 0.028.. Test accuracy: 0.995\n",
      "Epoch 9/10.. Train loss: 0.195.. Test loss: 0.032.. Test accuracy: 0.986\n",
      "Epoch 9/10.. Train loss: 0.306.. Test loss: 0.024.. Test accuracy: 0.994\n",
      "Epoch 9/10.. Train loss: 0.098.. Test loss: 0.026.. Test accuracy: 0.992\n",
      "Epoch 9/10.. Train loss: 0.090.. Test loss: 0.029.. Test accuracy: 0.988\n",
      "Epoch 9/10.. Train loss: 0.197.. Test loss: 0.026.. Test accuracy: 0.992\n",
      "Epoch 9/10.. Train loss: 0.105.. Test loss: 0.026.. Test accuracy: 0.991\n",
      "Epoch 9/10.. Train loss: 0.073.. Test loss: 0.023.. Test accuracy: 0.995\n",
      "Epoch 9/10.. Train loss: 0.079.. Test loss: 0.026.. Test accuracy: 0.992\n",
      "Epoch 9/10.. Train loss: 0.065.. Test loss: 0.026.. Test accuracy: 0.989\n",
      "Epoch 9/10.. Train loss: 0.169.. Test loss: 0.030.. Test accuracy: 0.989\n",
      "Epoch 9/10.. Train loss: 0.089.. Test loss: 0.025.. Test accuracy: 0.994\n",
      "Epoch 9/10.. Train loss: 0.134.. Test loss: 0.027.. Test accuracy: 0.992\n",
      "Epoch 9/10.. Train loss: 0.123.. Test loss: 0.027.. Test accuracy: 0.994\n",
      "Epoch 9/10.. Train loss: 0.071.. Test loss: 0.024.. Test accuracy: 0.995\n",
      "Epoch 9/10.. Train loss: 0.136.. Test loss: 0.027.. Test accuracy: 0.993\n",
      "Epoch 9/10.. Train loss: 0.121.. Test loss: 0.028.. Test accuracy: 0.992\n",
      "Epoch 9/10.. Train loss: 0.051.. Test loss: 0.028.. Test accuracy: 0.991\n",
      "Epoch 9/10.. Train loss: 0.125.. Test loss: 0.027.. Test accuracy: 0.989\n",
      "Epoch 9/10.. Train loss: 0.124.. Test loss: 0.028.. Test accuracy: 0.989\n",
      "Epoch 9/10.. Train loss: 0.186.. Test loss: 0.023.. Test accuracy: 0.994\n",
      "Epoch 9/10.. Train loss: 0.101.. Test loss: 0.028.. Test accuracy: 0.992\n",
      "Epoch 9/10.. Train loss: 0.096.. Test loss: 0.027.. Test accuracy: 0.990\n",
      "Epoch 9/10.. Train loss: 0.089.. Test loss: 0.033.. Test accuracy: 0.989\n",
      "Epoch 9/10.. Train loss: 0.176.. Test loss: 0.030.. Test accuracy: 0.990\n",
      "Epoch 9/10.. Train loss: 0.134.. Test loss: 0.021.. Test accuracy: 0.993\n",
      "Epoch 9/10.. Train loss: 0.067.. Test loss: 0.034.. Test accuracy: 0.987\n",
      "Epoch 9/10.. Train loss: 0.073.. Test loss: 0.023.. Test accuracy: 0.994\n",
      "Epoch 9/10.. Train loss: 0.094.. Test loss: 0.031.. Test accuracy: 0.990\n",
      "Epoch 9/10.. Train loss: 0.080.. Test loss: 0.029.. Test accuracy: 0.990\n",
      "Epoch 9/10.. Train loss: 0.084.. Test loss: 0.031.. Test accuracy: 0.992\n",
      "Epoch 9/10.. Train loss: 0.118.. Test loss: 0.029.. Test accuracy: 0.992\n",
      "Epoch 9/10.. Train loss: 0.096.. Test loss: 0.026.. Test accuracy: 0.992\n",
      "Epoch 9/10.. Train loss: 0.134.. Test loss: 0.032.. Test accuracy: 0.989\n",
      "Epoch 10/10.. Train loss: 0.204.. Test loss: 0.026.. Test accuracy: 0.989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10.. Train loss: 0.118.. Test loss: 0.021.. Test accuracy: 0.993\n",
      "Epoch 10/10.. Train loss: 0.092.. Test loss: 0.024.. Test accuracy: 0.993\n",
      "Epoch 10/10.. Train loss: 0.122.. Test loss: 0.033.. Test accuracy: 0.991\n",
      "Epoch 10/10.. Train loss: 0.144.. Test loss: 0.022.. Test accuracy: 0.994\n",
      "Epoch 10/10.. Train loss: 0.107.. Test loss: 0.029.. Test accuracy: 0.990\n",
      "Epoch 10/10.. Train loss: 0.211.. Test loss: 0.028.. Test accuracy: 0.990\n",
      "Epoch 10/10.. Train loss: 0.157.. Test loss: 0.029.. Test accuracy: 0.993\n",
      "Epoch 10/10.. Train loss: 0.112.. Test loss: 0.032.. Test accuracy: 0.991\n",
      "Epoch 10/10.. Train loss: 0.046.. Test loss: 0.036.. Test accuracy: 0.988\n",
      "Epoch 10/10.. Train loss: 0.107.. Test loss: 0.025.. Test accuracy: 0.990\n",
      "Epoch 10/10.. Train loss: 0.093.. Test loss: 0.030.. Test accuracy: 0.990\n",
      "Epoch 10/10.. Train loss: 0.059.. Test loss: 0.025.. Test accuracy: 0.993\n",
      "Epoch 10/10.. Train loss: 0.092.. Test loss: 0.029.. Test accuracy: 0.990\n",
      "Epoch 10/10.. Train loss: 0.120.. Test loss: 0.029.. Test accuracy: 0.990\n",
      "Epoch 10/10.. Train loss: 0.105.. Test loss: 0.026.. Test accuracy: 0.992\n",
      "Epoch 10/10.. Train loss: 0.098.. Test loss: 0.033.. Test accuracy: 0.988\n",
      "Epoch 10/10.. Train loss: 0.090.. Test loss: 0.028.. Test accuracy: 0.993\n",
      "Epoch 10/10.. Train loss: 0.192.. Test loss: 0.022.. Test accuracy: 0.995\n",
      "Epoch 10/10.. Train loss: 0.073.. Test loss: 0.025.. Test accuracy: 0.992\n",
      "Epoch 10/10.. Train loss: 0.114.. Test loss: 0.028.. Test accuracy: 0.992\n",
      "Epoch 10/10.. Train loss: 0.157.. Test loss: 0.022.. Test accuracy: 0.994\n",
      "Epoch 10/10.. Train loss: 0.167.. Test loss: 0.027.. Test accuracy: 0.993\n",
      "Epoch 10/10.. Train loss: 0.202.. Test loss: 0.025.. Test accuracy: 0.992\n",
      "Epoch 10/10.. Train loss: 0.062.. Test loss: 0.029.. Test accuracy: 0.993\n",
      "Epoch 10/10.. Train loss: 0.076.. Test loss: 0.028.. Test accuracy: 0.993\n",
      "Epoch 10/10.. Train loss: 0.117.. Test loss: 0.029.. Test accuracy: 0.989\n",
      "Epoch 10/10.. Train loss: 0.125.. Test loss: 0.026.. Test accuracy: 0.992\n",
      "Epoch 10/10.. Train loss: 0.074.. Test loss: 0.027.. Test accuracy: 0.992\n",
      "Epoch 10/10.. Train loss: 0.166.. Test loss: 0.026.. Test accuracy: 0.991\n",
      "Epoch 10/10.. Train loss: 0.097.. Test loss: 0.029.. Test accuracy: 0.991\n",
      "Epoch 10/10.. Train loss: 0.162.. Test loss: 0.026.. Test accuracy: 0.992\n",
      "Epoch 10/10.. Train loss: 0.086.. Test loss: 0.030.. Test accuracy: 0.992\n",
      "Epoch 10/10.. Train loss: 0.154.. Test loss: 0.028.. Test accuracy: 0.989\n",
      "Epoch 10/10.. Train loss: 0.163.. Test loss: 0.032.. Test accuracy: 0.990\n",
      "Epoch 10/10.. Train loss: 0.194.. Test loss: 0.028.. Test accuracy: 0.992\n",
      "Epoch 10/10.. Train loss: 0.104.. Test loss: 0.030.. Test accuracy: 0.990\n",
      "Epoch 10/10.. Train loss: 0.067.. Test loss: 0.022.. Test accuracy: 0.995\n",
      "Epoch 10/10.. Train loss: 0.099.. Test loss: 0.025.. Test accuracy: 0.994\n",
      "Epoch 10/10.. Train loss: 0.074.. Test loss: 0.021.. Test accuracy: 0.993\n",
      "Epoch 10/10.. Train loss: 0.103.. Test loss: 0.029.. Test accuracy: 0.990\n",
      "Epoch 10/10.. Train loss: 0.115.. Test loss: 0.029.. Test accuracy: 0.991\n",
      "Epoch 10/10.. Train loss: 0.083.. Test loss: 0.030.. Test accuracy: 0.989\n",
      "Epoch 10/10.. Train loss: 0.102.. Test loss: 0.022.. Test accuracy: 0.993\n",
      "Epoch 10/10.. Train loss: 0.374.. Test loss: 0.025.. Test accuracy: 0.991\n",
      "Epoch 10/10.. Train loss: 0.064.. Test loss: 0.029.. Test accuracy: 0.987\n",
      "Epoch 10/10.. Train loss: 0.055.. Test loss: 0.022.. Test accuracy: 0.991\n",
      "Epoch 10/10.. Train loss: 0.166.. Test loss: 0.027.. Test accuracy: 0.991\n",
      "Epoch 10/10.. Train loss: 0.098.. Test loss: 0.031.. Test accuracy: 0.984\n",
      "Epoch 10/10.. Train loss: 0.125.. Test loss: 0.027.. Test accuracy: 0.993\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 10\n",
    "train_losses, test_losses = [], []\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in trainloader:\n",
    "        steps += 1\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer_ft.zero_grad()\n",
    "        logps = model_ft.forward(inputs)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer_ft.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            model_ft.eval()\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in testloader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    logps = model_ft.forward(inputs)\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "                    test_loss += batch_loss.item()\n",
    "                    \n",
    "                    ps = torch.exp(logps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "            train_losses.append(running_loss/len(trainloader))\n",
    "            test_losses.append(test_loss/len(testloader))                    \n",
    "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "                  f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
    "            running_loss = 0\n",
    "            model_ft.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft, 'mask6_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
