{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['with_mask', 'without_mask']\n"
     ]
    }
   ],
   "source": [
    "data_dir = r'C:\\Users\\aiforesee\\Google Drive (bimapriambodowr@gmail.com)\\Digital Rise Indonesia\\Object Detection\\Masker Detection - Resnet\\experiements\\data'\n",
    "def load_split_train_test(datadir, valid_size = .25):\n",
    "    train_transforms = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                           transforms.CenterCrop(224),\n",
    "                                           transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0),\n",
    "                                           transforms.RandomAffine(degrees = (-45,45), translate=None, scale=None, shear=None, resample=False, fillcolor=0),\n",
    "                                           transforms.RandomRotation((-45,45)),\n",
    "                                           transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                           transforms.RandomPerspective(distortion_scale=0.5, p=0.5, interpolation=3, fill=0),\n",
    "                                           transforms.RandomVerticalFlip(p=0.5),\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False),\n",
    "                                           transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                          ])\n",
    "    test_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                          transforms.CenterCrop(224),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                         ])\n",
    "    train_data = datasets.ImageFolder(datadir,       \n",
    "                    transform=train_transforms)\n",
    "    test_data = datasets.ImageFolder(datadir,\n",
    "                    transform=test_transforms)\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "    train_idx, test_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "    trainloader = torch.utils.data.DataLoader(train_data,\n",
    "                   sampler=train_sampler, batch_size=8)\n",
    "    testloader = torch.utils.data.DataLoader(test_data,\n",
    "                   sampler=test_sampler, batch_size=8)\n",
    "    return trainloader, testloader\n",
    "trainloader, testloader = load_split_train_test(data_dir, .25)\n",
    "print(trainloader.dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "num_frts = model_ft.classifier[1].in_features #mobilenet\n",
    "model_ft.classifier[1] = nn.Linear(num_frts, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer_ft = optim.Adagrad(model_ft.parameters(), lr=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2(\n",
      "  (features): Sequential(\n",
      "    (0): ConvBNReLU(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (16): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (17): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): ConvBNReLU(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): ConvBNReLU(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (18): ConvBNReLU(\n",
      "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=1280, out_features=2, bias=True)\n",
      "  )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10.. Train loss: 0.722.. Test loss: 0.309.. Test accuracy: 0.818\n",
      "Epoch 1/10.. Train loss: 0.424.. Test loss: 0.161.. Test accuracy: 0.958\n",
      "Epoch 1/10.. Train loss: 0.355.. Test loss: 0.120.. Test accuracy: 0.970\n",
      "Epoch 1/10.. Train loss: 0.305.. Test loss: 0.085.. Test accuracy: 0.991\n",
      "Epoch 1/10.. Train loss: 0.358.. Test loss: 0.081.. Test accuracy: 0.995\n",
      "Epoch 1/10.. Train loss: 0.361.. Test loss: 0.061.. Test accuracy: 0.977\n",
      "Epoch 1/10.. Train loss: 0.302.. Test loss: 0.035.. Test accuracy: 0.997\n",
      "Epoch 1/10.. Train loss: 0.208.. Test loss: 0.031.. Test accuracy: 0.999\n",
      "Epoch 1/10.. Train loss: 0.158.. Test loss: 0.039.. Test accuracy: 0.999\n",
      "Epoch 1/10.. Train loss: 0.292.. Test loss: 0.039.. Test accuracy: 0.990\n",
      "Epoch 1/10.. Train loss: 0.309.. Test loss: 0.019.. Test accuracy: 0.999\n",
      "Epoch 1/10.. Train loss: 0.358.. Test loss: 0.018.. Test accuracy: 0.998\n",
      "Epoch 1/10.. Train loss: 0.256.. Test loss: 0.026.. Test accuracy: 0.996\n",
      "Epoch 1/10.. Train loss: 0.343.. Test loss: 0.025.. Test accuracy: 0.998\n",
      "Epoch 1/10.. Train loss: 0.269.. Test loss: 0.016.. Test accuracy: 0.998\n",
      "Epoch 1/10.. Train loss: 0.296.. Test loss: 0.019.. Test accuracy: 0.999\n",
      "Epoch 1/10.. Train loss: 0.224.. Test loss: 0.032.. Test accuracy: 0.997\n",
      "Epoch 1/10.. Train loss: 0.272.. Test loss: 0.017.. Test accuracy: 0.998\n",
      "Epoch 1/10.. Train loss: 0.270.. Test loss: 0.020.. Test accuracy: 0.996\n",
      "Epoch 1/10.. Train loss: 0.236.. Test loss: 0.016.. Test accuracy: 0.996\n",
      "Epoch 1/10.. Train loss: 0.346.. Test loss: 0.011.. Test accuracy: 0.999\n",
      "Epoch 1/10.. Train loss: 0.249.. Test loss: 0.023.. Test accuracy: 0.997\n",
      "Epoch 1/10.. Train loss: 0.119.. Test loss: 0.012.. Test accuracy: 0.999\n",
      "Epoch 1/10.. Train loss: 0.248.. Test loss: 0.012.. Test accuracy: 1.000\n",
      "Epoch 1/10.. Train loss: 0.260.. Test loss: 0.023.. Test accuracy: 0.992\n",
      "Epoch 1/10.. Train loss: 0.262.. Test loss: 0.012.. Test accuracy: 0.998\n",
      "Epoch 1/10.. Train loss: 0.244.. Test loss: 0.031.. Test accuracy: 0.992\n",
      "Epoch 1/10.. Train loss: 0.172.. Test loss: 0.012.. Test accuracy: 0.999\n",
      "Epoch 1/10.. Train loss: 0.338.. Test loss: 0.027.. Test accuracy: 1.000\n",
      "Epoch 1/10.. Train loss: 0.203.. Test loss: 0.015.. Test accuracy: 1.000\n",
      "Epoch 1/10.. Train loss: 0.169.. Test loss: 0.012.. Test accuracy: 1.000\n",
      "Epoch 1/10.. Train loss: 0.152.. Test loss: 0.020.. Test accuracy: 0.998\n",
      "Epoch 1/10.. Train loss: 0.249.. Test loss: 0.018.. Test accuracy: 0.996\n",
      "Epoch 1/10.. Train loss: 0.170.. Test loss: 0.041.. Test accuracy: 0.991\n",
      "Epoch 1/10.. Train loss: 0.172.. Test loss: 0.032.. Test accuracy: 0.990\n",
      "Epoch 1/10.. Train loss: 0.209.. Test loss: 0.013.. Test accuracy: 0.997\n",
      "Epoch 1/10.. Train loss: 0.209.. Test loss: 0.010.. Test accuracy: 0.999\n",
      "Epoch 2/10.. Train loss: 0.154.. Test loss: 0.012.. Test accuracy: 0.998\n",
      "Epoch 2/10.. Train loss: 0.162.. Test loss: 0.011.. Test accuracy: 0.999\n",
      "Epoch 2/10.. Train loss: 0.122.. Test loss: 0.010.. Test accuracy: 1.000\n",
      "Epoch 2/10.. Train loss: 0.119.. Test loss: 0.011.. Test accuracy: 1.000\n",
      "Epoch 2/10.. Train loss: 0.192.. Test loss: 0.009.. Test accuracy: 1.000\n",
      "Epoch 2/10.. Train loss: 0.378.. Test loss: 0.025.. Test accuracy: 0.998\n",
      "Epoch 2/10.. Train loss: 0.223.. Test loss: 0.023.. Test accuracy: 0.998\n",
      "Epoch 2/10.. Train loss: 0.187.. Test loss: 0.014.. Test accuracy: 0.999\n",
      "Epoch 2/10.. Train loss: 0.130.. Test loss: 0.014.. Test accuracy: 0.999\n",
      "Epoch 2/10.. Train loss: 0.164.. Test loss: 0.028.. Test accuracy: 0.993\n",
      "Epoch 2/10.. Train loss: 0.111.. Test loss: 0.015.. Test accuracy: 0.999\n",
      "Epoch 2/10.. Train loss: 0.174.. Test loss: 0.017.. Test accuracy: 0.998\n",
      "Epoch 2/10.. Train loss: 0.195.. Test loss: 0.024.. Test accuracy: 0.997\n",
      "Epoch 2/10.. Train loss: 0.184.. Test loss: 0.019.. Test accuracy: 0.999\n",
      "Epoch 2/10.. Train loss: 0.147.. Test loss: 0.014.. Test accuracy: 0.998\n",
      "Epoch 2/10.. Train loss: 0.173.. Test loss: 0.025.. Test accuracy: 0.992\n",
      "Epoch 2/10.. Train loss: 0.278.. Test loss: 0.029.. Test accuracy: 0.996\n",
      "Epoch 2/10.. Train loss: 0.221.. Test loss: 0.028.. Test accuracy: 0.997\n",
      "Epoch 2/10.. Train loss: 0.182.. Test loss: 0.018.. Test accuracy: 0.998\n",
      "Epoch 2/10.. Train loss: 0.142.. Test loss: 0.010.. Test accuracy: 1.000\n",
      "Epoch 2/10.. Train loss: 0.105.. Test loss: 0.011.. Test accuracy: 0.999\n",
      "Epoch 2/10.. Train loss: 0.174.. Test loss: 0.010.. Test accuracy: 1.000\n",
      "Epoch 2/10.. Train loss: 0.217.. Test loss: 0.008.. Test accuracy: 1.000\n",
      "Epoch 2/10.. Train loss: 0.142.. Test loss: 0.011.. Test accuracy: 1.000\n",
      "Epoch 2/10.. Train loss: 0.243.. Test loss: 0.009.. Test accuracy: 0.999\n",
      "Epoch 2/10.. Train loss: 0.118.. Test loss: 0.018.. Test accuracy: 0.999\n",
      "Epoch 2/10.. Train loss: 0.219.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 2/10.. Train loss: 0.244.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 2/10.. Train loss: 0.155.. Test loss: 0.006.. Test accuracy: 1.000\n",
      "Epoch 2/10.. Train loss: 0.191.. Test loss: 0.011.. Test accuracy: 0.999\n",
      "Epoch 2/10.. Train loss: 0.145.. Test loss: 0.008.. Test accuracy: 1.000\n",
      "Epoch 2/10.. Train loss: 0.135.. Test loss: 0.009.. Test accuracy: 0.999\n",
      "Epoch 2/10.. Train loss: 0.147.. Test loss: 0.012.. Test accuracy: 0.999\n",
      "Epoch 2/10.. Train loss: 0.132.. Test loss: 0.010.. Test accuracy: 0.999\n",
      "Epoch 2/10.. Train loss: 0.101.. Test loss: 0.012.. Test accuracy: 0.999\n",
      "Epoch 2/10.. Train loss: 0.239.. Test loss: 0.016.. Test accuracy: 0.997\n",
      "Epoch 2/10.. Train loss: 0.158.. Test loss: 0.018.. Test accuracy: 0.998\n",
      "Epoch 3/10.. Train loss: 0.104.. Test loss: 0.011.. Test accuracy: 0.999\n",
      "Epoch 3/10.. Train loss: 0.161.. Test loss: 0.016.. Test accuracy: 0.997\n",
      "Epoch 3/10.. Train loss: 0.131.. Test loss: 0.022.. Test accuracy: 0.995\n",
      "Epoch 3/10.. Train loss: 0.154.. Test loss: 0.009.. Test accuracy: 0.999\n",
      "Epoch 3/10.. Train loss: 0.277.. Test loss: 0.020.. Test accuracy: 0.995\n",
      "Epoch 3/10.. Train loss: 0.114.. Test loss: 0.014.. Test accuracy: 0.997\n",
      "Epoch 3/10.. Train loss: 0.190.. Test loss: 0.014.. Test accuracy: 0.998\n",
      "Epoch 3/10.. Train loss: 0.155.. Test loss: 0.009.. Test accuracy: 0.999\n",
      "Epoch 3/10.. Train loss: 0.086.. Test loss: 0.007.. Test accuracy: 1.000\n",
      "Epoch 3/10.. Train loss: 0.203.. Test loss: 0.009.. Test accuracy: 0.999\n",
      "Epoch 3/10.. Train loss: 0.161.. Test loss: 0.024.. Test accuracy: 0.995\n",
      "Epoch 3/10.. Train loss: 0.259.. Test loss: 0.029.. Test accuracy: 0.993\n",
      "Epoch 3/10.. Train loss: 0.147.. Test loss: 0.015.. Test accuracy: 0.998\n",
      "Epoch 3/10.. Train loss: 0.083.. Test loss: 0.010.. Test accuracy: 0.999\n",
      "Epoch 3/10.. Train loss: 0.110.. Test loss: 0.013.. Test accuracy: 0.999\n",
      "Epoch 3/10.. Train loss: 0.158.. Test loss: 0.014.. Test accuracy: 0.997\n",
      "Epoch 3/10.. Train loss: 0.156.. Test loss: 0.013.. Test accuracy: 0.997\n",
      "Epoch 3/10.. Train loss: 0.138.. Test loss: 0.028.. Test accuracy: 0.996\n",
      "Epoch 3/10.. Train loss: 0.197.. Test loss: 0.013.. Test accuracy: 0.998\n",
      "Epoch 3/10.. Train loss: 0.083.. Test loss: 0.022.. Test accuracy: 0.996\n",
      "Epoch 3/10.. Train loss: 0.112.. Test loss: 0.010.. Test accuracy: 0.999\n",
      "Epoch 3/10.. Train loss: 0.116.. Test loss: 0.017.. Test accuracy: 0.995\n",
      "Epoch 3/10.. Train loss: 0.157.. Test loss: 0.039.. Test accuracy: 0.994\n",
      "Epoch 3/10.. Train loss: 0.135.. Test loss: 0.033.. Test accuracy: 0.997\n",
      "Epoch 3/10.. Train loss: 0.077.. Test loss: 0.015.. Test accuracy: 0.999\n",
      "Epoch 3/10.. Train loss: 0.197.. Test loss: 0.025.. Test accuracy: 0.999\n",
      "Epoch 3/10.. Train loss: 0.087.. Test loss: 0.017.. Test accuracy: 0.999\n",
      "Epoch 3/10.. Train loss: 0.201.. Test loss: 0.018.. Test accuracy: 0.999\n",
      "Epoch 3/10.. Train loss: 0.061.. Test loss: 0.011.. Test accuracy: 0.999\n",
      "Epoch 3/10.. Train loss: 0.213.. Test loss: 0.008.. Test accuracy: 1.000\n",
      "Epoch 3/10.. Train loss: 0.118.. Test loss: 0.009.. Test accuracy: 1.000\n",
      "Epoch 3/10.. Train loss: 0.464.. Test loss: 0.022.. Test accuracy: 0.999\n",
      "Epoch 3/10.. Train loss: 0.150.. Test loss: 0.034.. Test accuracy: 0.997\n",
      "Epoch 3/10.. Train loss: 0.143.. Test loss: 0.021.. Test accuracy: 0.998\n",
      "Epoch 3/10.. Train loss: 0.124.. Test loss: 0.009.. Test accuracy: 0.999\n",
      "Epoch 3/10.. Train loss: 0.176.. Test loss: 0.020.. Test accuracy: 0.998\n",
      "Epoch 3/10.. Train loss: 0.123.. Test loss: 0.034.. Test accuracy: 0.997\n",
      "Epoch 4/10.. Train loss: 0.418.. Test loss: 0.024.. Test accuracy: 0.999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10.. Train loss: 0.155.. Test loss: 0.095.. Test accuracy: 0.977\n",
      "Epoch 4/10.. Train loss: 0.121.. Test loss: 0.045.. Test accuracy: 0.995\n",
      "Epoch 4/10.. Train loss: 0.147.. Test loss: 0.023.. Test accuracy: 0.998\n",
      "Epoch 4/10.. Train loss: 0.146.. Test loss: 0.027.. Test accuracy: 0.998\n",
      "Epoch 4/10.. Train loss: 0.167.. Test loss: 0.051.. Test accuracy: 0.995\n",
      "Epoch 4/10.. Train loss: 0.295.. Test loss: 0.038.. Test accuracy: 0.998\n",
      "Epoch 4/10.. Train loss: 0.083.. Test loss: 0.019.. Test accuracy: 0.998\n",
      "Epoch 4/10.. Train loss: 0.101.. Test loss: 0.030.. Test accuracy: 0.998\n",
      "Epoch 4/10.. Train loss: 0.089.. Test loss: 0.065.. Test accuracy: 0.989\n",
      "Epoch 4/10.. Train loss: 0.148.. Test loss: 0.085.. Test accuracy: 0.973\n",
      "Epoch 4/10.. Train loss: 0.082.. Test loss: 0.025.. Test accuracy: 0.997\n",
      "Epoch 4/10.. Train loss: 0.183.. Test loss: 0.010.. Test accuracy: 0.999\n",
      "Epoch 4/10.. Train loss: 0.109.. Test loss: 0.022.. Test accuracy: 0.998\n",
      "Epoch 4/10.. Train loss: 0.091.. Test loss: 0.014.. Test accuracy: 0.999\n",
      "Epoch 4/10.. Train loss: 0.131.. Test loss: 0.009.. Test accuracy: 0.999\n",
      "Epoch 4/10.. Train loss: 0.126.. Test loss: 0.005.. Test accuracy: 0.999\n",
      "Epoch 4/10.. Train loss: 0.159.. Test loss: 0.022.. Test accuracy: 0.996\n",
      "Epoch 4/10.. Train loss: 0.112.. Test loss: 0.025.. Test accuracy: 0.996\n",
      "Epoch 4/10.. Train loss: 0.128.. Test loss: 0.019.. Test accuracy: 0.998\n",
      "Epoch 4/10.. Train loss: 0.075.. Test loss: 0.018.. Test accuracy: 0.998\n",
      "Epoch 4/10.. Train loss: 0.159.. Test loss: 0.019.. Test accuracy: 0.998\n",
      "Epoch 4/10.. Train loss: 0.141.. Test loss: 0.031.. Test accuracy: 0.997\n",
      "Epoch 4/10.. Train loss: 0.111.. Test loss: 0.018.. Test accuracy: 0.998\n",
      "Epoch 4/10.. Train loss: 0.100.. Test loss: 0.016.. Test accuracy: 0.999\n",
      "Epoch 4/10.. Train loss: 0.098.. Test loss: 0.009.. Test accuracy: 0.999\n",
      "Epoch 4/10.. Train loss: 0.042.. Test loss: 0.010.. Test accuracy: 0.999\n",
      "Epoch 4/10.. Train loss: 0.125.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 4/10.. Train loss: 0.174.. Test loss: 0.007.. Test accuracy: 1.000\n",
      "Epoch 4/10.. Train loss: 0.152.. Test loss: 0.004.. Test accuracy: 1.000\n",
      "Epoch 4/10.. Train loss: 0.159.. Test loss: 0.006.. Test accuracy: 0.999\n",
      "Epoch 4/10.. Train loss: 0.086.. Test loss: 0.004.. Test accuracy: 1.000\n",
      "Epoch 4/10.. Train loss: 0.083.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 4/10.. Train loss: 0.283.. Test loss: 0.009.. Test accuracy: 0.998\n",
      "Epoch 4/10.. Train loss: 0.051.. Test loss: 0.006.. Test accuracy: 0.999\n",
      "Epoch 4/10.. Train loss: 0.113.. Test loss: 0.010.. Test accuracy: 0.997\n",
      "Epoch 4/10.. Train loss: 0.136.. Test loss: 0.013.. Test accuracy: 0.997\n",
      "Epoch 5/10.. Train loss: 0.369.. Test loss: 0.010.. Test accuracy: 0.997\n",
      "Epoch 5/10.. Train loss: 0.106.. Test loss: 0.010.. Test accuracy: 0.998\n",
      "Epoch 5/10.. Train loss: 0.050.. Test loss: 0.009.. Test accuracy: 0.999\n",
      "Epoch 5/10.. Train loss: 0.124.. Test loss: 0.010.. Test accuracy: 0.998\n",
      "Epoch 5/10.. Train loss: 0.181.. Test loss: 0.012.. Test accuracy: 0.999\n",
      "Epoch 5/10.. Train loss: 0.097.. Test loss: 0.006.. Test accuracy: 0.999\n",
      "Epoch 5/10.. Train loss: 0.149.. Test loss: 0.009.. Test accuracy: 0.999\n",
      "Epoch 5/10.. Train loss: 0.113.. Test loss: 0.011.. Test accuracy: 0.999\n",
      "Epoch 5/10.. Train loss: 0.077.. Test loss: 0.008.. Test accuracy: 1.000\n",
      "Epoch 5/10.. Train loss: 0.098.. Test loss: 0.012.. Test accuracy: 0.999\n",
      "Epoch 5/10.. Train loss: 0.090.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 5/10.. Train loss: 0.129.. Test loss: 0.012.. Test accuracy: 0.998\n",
      "Epoch 5/10.. Train loss: 0.123.. Test loss: 0.018.. Test accuracy: 0.997\n",
      "Epoch 5/10.. Train loss: 0.084.. Test loss: 0.024.. Test accuracy: 0.997\n",
      "Epoch 5/10.. Train loss: 0.112.. Test loss: 0.010.. Test accuracy: 0.998\n",
      "Epoch 5/10.. Train loss: 0.038.. Test loss: 0.011.. Test accuracy: 0.997\n",
      "Epoch 5/10.. Train loss: 0.100.. Test loss: 0.026.. Test accuracy: 0.996\n",
      "Epoch 5/10.. Train loss: 0.092.. Test loss: 0.013.. Test accuracy: 0.996\n",
      "Epoch 5/10.. Train loss: 0.094.. Test loss: 0.031.. Test accuracy: 0.995\n",
      "Epoch 5/10.. Train loss: 0.148.. Test loss: 0.014.. Test accuracy: 0.997\n",
      "Epoch 5/10.. Train loss: 0.200.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 5/10.. Train loss: 0.084.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 5/10.. Train loss: 0.205.. Test loss: 0.006.. Test accuracy: 1.000\n",
      "Epoch 5/10.. Train loss: 0.095.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 5/10.. Train loss: 0.208.. Test loss: 0.007.. Test accuracy: 0.999\n",
      "Epoch 5/10.. Train loss: 0.122.. Test loss: 0.006.. Test accuracy: 1.000\n",
      "Epoch 5/10.. Train loss: 0.247.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 5/10.. Train loss: 0.072.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 5/10.. Train loss: 0.090.. Test loss: 0.004.. Test accuracy: 1.000\n",
      "Epoch 5/10.. Train loss: 0.122.. Test loss: 0.004.. Test accuracy: 1.000\n",
      "Epoch 5/10.. Train loss: 0.058.. Test loss: 0.006.. Test accuracy: 0.999\n",
      "Epoch 5/10.. Train loss: 0.123.. Test loss: 0.006.. Test accuracy: 0.999\n",
      "Epoch 5/10.. Train loss: 0.114.. Test loss: 0.004.. Test accuracy: 0.999\n",
      "Epoch 5/10.. Train loss: 0.090.. Test loss: 0.007.. Test accuracy: 0.999\n",
      "Epoch 5/10.. Train loss: 0.142.. Test loss: 0.008.. Test accuracy: 0.998\n",
      "Epoch 5/10.. Train loss: 0.065.. Test loss: 0.011.. Test accuracy: 0.998\n",
      "Epoch 5/10.. Train loss: 0.079.. Test loss: 0.015.. Test accuracy: 0.997\n",
      "Epoch 6/10.. Train loss: 0.357.. Test loss: 0.012.. Test accuracy: 0.996\n",
      "Epoch 6/10.. Train loss: 0.144.. Test loss: 0.009.. Test accuracy: 0.999\n",
      "Epoch 6/10.. Train loss: 0.100.. Test loss: 0.008.. Test accuracy: 0.999\n",
      "Epoch 6/10.. Train loss: 0.078.. Test loss: 0.008.. Test accuracy: 0.999\n",
      "Epoch 6/10.. Train loss: 0.093.. Test loss: 0.006.. Test accuracy: 0.999\n",
      "Epoch 6/10.. Train loss: 0.064.. Test loss: 0.006.. Test accuracy: 0.999\n",
      "Epoch 6/10.. Train loss: 0.054.. Test loss: 0.007.. Test accuracy: 0.999\n",
      "Epoch 6/10.. Train loss: 0.101.. Test loss: 0.006.. Test accuracy: 1.000\n",
      "Epoch 6/10.. Train loss: 0.057.. Test loss: 0.007.. Test accuracy: 0.999\n",
      "Epoch 6/10.. Train loss: 0.149.. Test loss: 0.006.. Test accuracy: 0.999\n",
      "Epoch 6/10.. Train loss: 0.076.. Test loss: 0.006.. Test accuracy: 0.999\n",
      "Epoch 6/10.. Train loss: 0.123.. Test loss: 0.004.. Test accuracy: 1.000\n",
      "Epoch 6/10.. Train loss: 0.034.. Test loss: 0.004.. Test accuracy: 1.000\n",
      "Epoch 6/10.. Train loss: 0.074.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 6/10.. Train loss: 0.226.. Test loss: 0.004.. Test accuracy: 1.000\n",
      "Epoch 6/10.. Train loss: 0.185.. Test loss: 0.006.. Test accuracy: 0.999\n",
      "Epoch 6/10.. Train loss: 0.175.. Test loss: 0.008.. Test accuracy: 0.999\n",
      "Epoch 6/10.. Train loss: 0.113.. Test loss: 0.011.. Test accuracy: 0.999\n",
      "Epoch 6/10.. Train loss: 0.091.. Test loss: 0.010.. Test accuracy: 0.999\n",
      "Epoch 6/10.. Train loss: 0.096.. Test loss: 0.014.. Test accuracy: 0.998\n",
      "Epoch 6/10.. Train loss: 0.094.. Test loss: 0.011.. Test accuracy: 0.999\n",
      "Epoch 6/10.. Train loss: 0.218.. Test loss: 0.007.. Test accuracy: 0.999\n",
      "Epoch 6/10.. Train loss: 0.076.. Test loss: 0.008.. Test accuracy: 0.999\n",
      "Epoch 6/10.. Train loss: 0.105.. Test loss: 0.008.. Test accuracy: 0.999\n",
      "Epoch 6/10.. Train loss: 0.130.. Test loss: 0.008.. Test accuracy: 0.999\n",
      "Epoch 6/10.. Train loss: 0.087.. Test loss: 0.012.. Test accuracy: 0.998\n",
      "Epoch 6/10.. Train loss: 0.054.. Test loss: 0.011.. Test accuracy: 0.998\n",
      "Epoch 6/10.. Train loss: 0.095.. Test loss: 0.011.. Test accuracy: 0.999\n",
      "Epoch 6/10.. Train loss: 0.128.. Test loss: 0.009.. Test accuracy: 0.999\n",
      "Epoch 6/10.. Train loss: 0.098.. Test loss: 0.006.. Test accuracy: 0.999\n",
      "Epoch 6/10.. Train loss: 0.139.. Test loss: 0.009.. Test accuracy: 0.999\n",
      "Epoch 6/10.. Train loss: 0.071.. Test loss: 0.015.. Test accuracy: 0.999\n",
      "Epoch 6/10.. Train loss: 0.107.. Test loss: 0.012.. Test accuracy: 0.999\n",
      "Epoch 6/10.. Train loss: 0.068.. Test loss: 0.011.. Test accuracy: 0.999\n",
      "Epoch 6/10.. Train loss: 0.097.. Test loss: 0.018.. Test accuracy: 0.999\n",
      "Epoch 6/10.. Train loss: 0.111.. Test loss: 0.007.. Test accuracy: 0.999\n",
      "Epoch 6/10.. Train loss: 0.074.. Test loss: 0.012.. Test accuracy: 0.998\n",
      "Epoch 7/10.. Train loss: 0.187.. Test loss: 0.009.. Test accuracy: 0.999\n",
      "Epoch 7/10.. Train loss: 0.069.. Test loss: 0.008.. Test accuracy: 0.999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10.. Train loss: 0.057.. Test loss: 0.006.. Test accuracy: 1.000\n",
      "Epoch 7/10.. Train loss: 0.181.. Test loss: 0.027.. Test accuracy: 0.997\n",
      "Epoch 7/10.. Train loss: 0.081.. Test loss: 0.013.. Test accuracy: 0.999\n",
      "Epoch 7/10.. Train loss: 0.094.. Test loss: 0.006.. Test accuracy: 0.999\n",
      "Epoch 7/10.. Train loss: 0.096.. Test loss: 0.005.. Test accuracy: 0.999\n",
      "Epoch 7/10.. Train loss: 0.105.. Test loss: 0.009.. Test accuracy: 0.998\n",
      "Epoch 7/10.. Train loss: 0.029.. Test loss: 0.009.. Test accuracy: 0.997\n",
      "Epoch 7/10.. Train loss: 0.136.. Test loss: 0.031.. Test accuracy: 0.995\n",
      "Epoch 7/10.. Train loss: 0.089.. Test loss: 0.017.. Test accuracy: 0.997\n",
      "Epoch 7/10.. Train loss: 0.109.. Test loss: 0.007.. Test accuracy: 0.999\n",
      "Epoch 7/10.. Train loss: 0.193.. Test loss: 0.007.. Test accuracy: 1.000\n",
      "Epoch 7/10.. Train loss: 0.213.. Test loss: 0.003.. Test accuracy: 1.000\n",
      "Epoch 7/10.. Train loss: 0.079.. Test loss: 0.004.. Test accuracy: 1.000\n",
      "Epoch 7/10.. Train loss: 0.048.. Test loss: 0.006.. Test accuracy: 1.000\n",
      "Epoch 7/10.. Train loss: 0.046.. Test loss: 0.004.. Test accuracy: 1.000\n",
      "Epoch 7/10.. Train loss: 0.089.. Test loss: 0.009.. Test accuracy: 0.998\n",
      "Epoch 7/10.. Train loss: 0.102.. Test loss: 0.010.. Test accuracy: 0.999\n",
      "Epoch 7/10.. Train loss: 0.046.. Test loss: 0.006.. Test accuracy: 1.000\n",
      "Epoch 7/10.. Train loss: 0.110.. Test loss: 0.004.. Test accuracy: 1.000\n",
      "Epoch 7/10.. Train loss: 0.074.. Test loss: 0.007.. Test accuracy: 1.000\n",
      "Epoch 7/10.. Train loss: 0.157.. Test loss: 0.006.. Test accuracy: 1.000\n",
      "Epoch 7/10.. Train loss: 0.116.. Test loss: 0.015.. Test accuracy: 0.999\n",
      "Epoch 7/10.. Train loss: 0.058.. Test loss: 0.009.. Test accuracy: 1.000\n",
      "Epoch 7/10.. Train loss: 0.106.. Test loss: 0.013.. Test accuracy: 1.000\n",
      "Epoch 7/10.. Train loss: 0.220.. Test loss: 0.004.. Test accuracy: 1.000\n",
      "Epoch 7/10.. Train loss: 0.064.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 7/10.. Train loss: 0.063.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 7/10.. Train loss: 0.068.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 7/10.. Train loss: 0.096.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 7/10.. Train loss: 0.153.. Test loss: 0.003.. Test accuracy: 1.000\n",
      "Epoch 7/10.. Train loss: 0.089.. Test loss: 0.006.. Test accuracy: 1.000\n",
      "Epoch 7/10.. Train loss: 0.069.. Test loss: 0.003.. Test accuracy: 1.000\n",
      "Epoch 7/10.. Train loss: 0.142.. Test loss: 0.006.. Test accuracy: 1.000\n",
      "Epoch 7/10.. Train loss: 0.123.. Test loss: 0.017.. Test accuracy: 0.998\n",
      "Epoch 7/10.. Train loss: 0.027.. Test loss: 0.008.. Test accuracy: 1.000\n",
      "Epoch 8/10.. Train loss: 0.073.. Test loss: 0.006.. Test accuracy: 0.999\n",
      "Epoch 8/10.. Train loss: 0.237.. Test loss: 0.004.. Test accuracy: 1.000\n",
      "Epoch 8/10.. Train loss: 0.120.. Test loss: 0.005.. Test accuracy: 0.999\n",
      "Epoch 8/10.. Train loss: 0.088.. Test loss: 0.004.. Test accuracy: 0.999\n",
      "Epoch 8/10.. Train loss: 0.134.. Test loss: 0.011.. Test accuracy: 0.998\n",
      "Epoch 8/10.. Train loss: 0.123.. Test loss: 0.008.. Test accuracy: 0.998\n",
      "Epoch 8/10.. Train loss: 0.133.. Test loss: 0.005.. Test accuracy: 0.999\n",
      "Epoch 8/10.. Train loss: 0.083.. Test loss: 0.005.. Test accuracy: 0.999\n",
      "Epoch 8/10.. Train loss: 0.187.. Test loss: 0.006.. Test accuracy: 0.999\n",
      "Epoch 8/10.. Train loss: 0.073.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 8/10.. Train loss: 0.151.. Test loss: 0.004.. Test accuracy: 1.000\n",
      "Epoch 8/10.. Train loss: 0.112.. Test loss: 0.003.. Test accuracy: 1.000\n",
      "Epoch 8/10.. Train loss: 0.120.. Test loss: 0.003.. Test accuracy: 1.000\n",
      "Epoch 8/10.. Train loss: 0.096.. Test loss: 0.006.. Test accuracy: 1.000\n",
      "Epoch 8/10.. Train loss: 0.110.. Test loss: 0.003.. Test accuracy: 1.000\n",
      "Epoch 8/10.. Train loss: 0.064.. Test loss: 0.003.. Test accuracy: 1.000\n",
      "Epoch 8/10.. Train loss: 0.051.. Test loss: 0.003.. Test accuracy: 1.000\n",
      "Epoch 8/10.. Train loss: 0.193.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 8/10.. Train loss: 0.079.. Test loss: 0.006.. Test accuracy: 0.999\n",
      "Epoch 8/10.. Train loss: 0.026.. Test loss: 0.004.. Test accuracy: 1.000\n",
      "Epoch 8/10.. Train loss: 0.185.. Test loss: 0.003.. Test accuracy: 1.000\n",
      "Epoch 8/10.. Train loss: 0.083.. Test loss: 0.002.. Test accuracy: 1.000\n",
      "Epoch 8/10.. Train loss: 0.060.. Test loss: 0.002.. Test accuracy: 1.000\n",
      "Epoch 8/10.. Train loss: 0.114.. Test loss: 0.002.. Test accuracy: 1.000\n",
      "Epoch 8/10.. Train loss: 0.043.. Test loss: 0.002.. Test accuracy: 1.000\n",
      "Epoch 8/10.. Train loss: 0.038.. Test loss: 0.003.. Test accuracy: 1.000\n",
      "Epoch 8/10.. Train loss: 0.078.. Test loss: 0.003.. Test accuracy: 1.000\n",
      "Epoch 8/10.. Train loss: 0.069.. Test loss: 0.003.. Test accuracy: 1.000\n",
      "Epoch 8/10.. Train loss: 0.090.. Test loss: 0.003.. Test accuracy: 1.000\n",
      "Epoch 8/10.. Train loss: 0.063.. Test loss: 0.003.. Test accuracy: 1.000\n",
      "Epoch 8/10.. Train loss: 0.028.. Test loss: 0.003.. Test accuracy: 1.000\n",
      "Epoch 8/10.. Train loss: 0.356.. Test loss: 0.003.. Test accuracy: 1.000\n",
      "Epoch 8/10.. Train loss: 0.098.. Test loss: 0.003.. Test accuracy: 1.000\n",
      "Epoch 8/10.. Train loss: 0.042.. Test loss: 0.003.. Test accuracy: 1.000\n",
      "Epoch 8/10.. Train loss: 0.054.. Test loss: 0.003.. Test accuracy: 1.000\n",
      "Epoch 8/10.. Train loss: 0.040.. Test loss: 0.003.. Test accuracy: 1.000\n",
      "Epoch 8/10.. Train loss: 0.059.. Test loss: 0.002.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.094.. Test loss: 0.003.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.066.. Test loss: 0.002.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.060.. Test loss: 0.002.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.032.. Test loss: 0.002.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.054.. Test loss: 0.003.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.129.. Test loss: 0.003.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.069.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.048.. Test loss: 0.004.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.068.. Test loss: 0.003.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.160.. Test loss: 0.004.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.124.. Test loss: 0.004.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.112.. Test loss: 0.004.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.144.. Test loss: 0.006.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.072.. Test loss: 0.006.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.069.. Test loss: 0.006.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.032.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.199.. Test loss: 0.004.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.129.. Test loss: 0.004.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.039.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.129.. Test loss: 0.004.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.058.. Test loss: 0.003.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.245.. Test loss: 0.003.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.131.. Test loss: 0.003.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.126.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.084.. Test loss: 0.004.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.060.. Test loss: 0.004.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.121.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.063.. Test loss: 0.004.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.064.. Test loss: 0.007.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.031.. Test loss: 0.006.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.067.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.086.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.131.. Test loss: 0.006.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.146.. Test loss: 0.006.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.073.. Test loss: 0.010.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.086.. Test loss: 0.011.. Test accuracy: 1.000\n",
      "Epoch 9/10.. Train loss: 0.162.. Test loss: 0.006.. Test accuracy: 1.000\n",
      "Epoch 10/10.. Train loss: 0.160.. Test loss: 0.004.. Test accuracy: 1.000\n",
      "Epoch 10/10.. Train loss: 0.045.. Test loss: 0.004.. Test accuracy: 1.000\n",
      "Epoch 10/10.. Train loss: 0.052.. Test loss: 0.003.. Test accuracy: 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10.. Train loss: 0.095.. Test loss: 0.004.. Test accuracy: 1.000\n",
      "Epoch 10/10.. Train loss: 0.067.. Test loss: 0.005.. Test accuracy: 0.999\n",
      "Epoch 10/10.. Train loss: 0.059.. Test loss: 0.006.. Test accuracy: 0.999\n",
      "Epoch 10/10.. Train loss: 0.094.. Test loss: 0.005.. Test accuracy: 0.999\n",
      "Epoch 10/10.. Train loss: 0.081.. Test loss: 0.007.. Test accuracy: 0.999\n",
      "Epoch 10/10.. Train loss: 0.116.. Test loss: 0.003.. Test accuracy: 1.000\n",
      "Epoch 10/10.. Train loss: 0.105.. Test loss: 0.004.. Test accuracy: 1.000\n",
      "Epoch 10/10.. Train loss: 0.109.. Test loss: 0.004.. Test accuracy: 1.000\n",
      "Epoch 10/10.. Train loss: 0.053.. Test loss: 0.004.. Test accuracy: 1.000\n",
      "Epoch 10/10.. Train loss: 0.052.. Test loss: 0.004.. Test accuracy: 0.999\n",
      "Epoch 10/10.. Train loss: 0.106.. Test loss: 0.004.. Test accuracy: 0.999\n",
      "Epoch 10/10.. Train loss: 0.064.. Test loss: 0.003.. Test accuracy: 1.000\n",
      "Epoch 10/10.. Train loss: 0.120.. Test loss: 0.003.. Test accuracy: 1.000\n",
      "Epoch 10/10.. Train loss: 0.056.. Test loss: 0.004.. Test accuracy: 1.000\n",
      "Epoch 10/10.. Train loss: 0.136.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 10/10.. Train loss: 0.078.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 10/10.. Train loss: 0.093.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 10/10.. Train loss: 0.121.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 10/10.. Train loss: 0.061.. Test loss: 0.004.. Test accuracy: 1.000\n",
      "Epoch 10/10.. Train loss: 0.144.. Test loss: 0.004.. Test accuracy: 1.000\n",
      "Epoch 10/10.. Train loss: 0.101.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 10/10.. Train loss: 0.084.. Test loss: 0.006.. Test accuracy: 1.000\n",
      "Epoch 10/10.. Train loss: 0.171.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 10/10.. Train loss: 0.083.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 10/10.. Train loss: 0.127.. Test loss: 0.006.. Test accuracy: 1.000\n",
      "Epoch 10/10.. Train loss: 0.119.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 10/10.. Train loss: 0.136.. Test loss: 0.006.. Test accuracy: 1.000\n",
      "Epoch 10/10.. Train loss: 0.149.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 10/10.. Train loss: 0.066.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 10/10.. Train loss: 0.071.. Test loss: 0.006.. Test accuracy: 1.000\n",
      "Epoch 10/10.. Train loss: 0.063.. Test loss: 0.005.. Test accuracy: 1.000\n",
      "Epoch 10/10.. Train loss: 0.136.. Test loss: 0.009.. Test accuracy: 1.000\n",
      "Epoch 10/10.. Train loss: 0.088.. Test loss: 0.007.. Test accuracy: 1.000\n",
      "Epoch 10/10.. Train loss: 0.072.. Test loss: 0.007.. Test accuracy: 1.000\n",
      "Epoch 10/10.. Train loss: 0.053.. Test loss: 0.006.. Test accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 10\n",
    "train_losses, test_losses = [], []\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in trainloader:\n",
    "        steps += 1\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer_ft.zero_grad()\n",
    "        logps = model_ft.forward(inputs)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer_ft.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            model_ft.eval()\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in testloader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    logps = model_ft.forward(inputs)\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "                    test_loss += batch_loss.item()\n",
    "                    \n",
    "                    ps = torch.exp(logps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "            train_losses.append(running_loss/len(trainloader))\n",
    "            test_losses.append(test_loss/len(testloader))                    \n",
    "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "                  f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
    "            running_loss = 0\n",
    "            model_ft.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_ft, 'mask5_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
